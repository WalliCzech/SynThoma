# gui/layout.py
"""
wAllICzech AI Studio 2025 â€“ GUI tak Å¡Ã­lenÄ› cool, Å¾e Matrix padÃ¡ zÃ¡vistÃ­! ğŸ¨
KompletnÃ­ verze s oranÅ¾ovo-ÄernÃ½m designem, pokroÄilÃ½mi funkcemi a Å vejkÅ¯v humor! ğŸ˜ˆ
"""
import gradio as gr
import logging
import cv2
import json
from pathlib import Path
from pytube import YouTube
import yt_dlp
from moviepy.editor import VideoFileClip
import numpy as np
import asyncio
from typing import List, Dict, Optional
from PIL import Image
import time
import os
import exifread
import mutagen
import torch
from core.image_processor import ImageProcessor
from core.flux_runner import FluxRunner
from core.sdxl_runner import SDXLRunner
from core.lipsync_engine import LipsyncEngine
from core.forensic_tools import ForensicTools
from core.segmenter import Segmenter
from core.video_exporter import VideoExporter
from core.audio_processor import AudioProcessor
from core.face_swapper import FaceSwapper
from core.upscaler import Upscaler
from core.expression_editor import ExpressionEditor
from utils.helpers import Config
from main import get_next_output_filename
import plotly.express as px  # NOVÃ‰: Pro vizualizaci phoneme timeline a deepfake skÃ³re
import pandas as pd  # NOVÃ‰: Pro export historie do CSV

logger = logging.getLogger(__name__)
logger.info("ğŸš€ GUI se rozjÃ­Å¾dÃ­... PÅ™ipni si pÃ¡sy, bude to pixelovÃ½ masakr! ğŸ”¥")

def get_file_metadata(file_path: str) -> str:
    """VytÃ¡hne metadata, nebo tÄ› poÅ¡le do pixelovÃ½ho pekla! ğŸ˜ˆ"""
    if not file_path or not Path(file_path).exists():
        return "â— Å½Ã¡dnÃ½ soubor, Å¾Ã¡dnÃ¡ zÃ¡bava! Nahraj nÄ›co, lenochu! ğŸ˜¤"
    
    metadata = []
    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
    metadata.append(f"ğŸ“ Velikost: {file_size:.2f} MB")
    
    try:
        if file_path.endswith((".jpg", ".jpeg", ".png")):
            with Image.open(file_path) as img:
                width, height = img.size
                metadata.append(f"ğŸ“ RozliÅ¡enÃ­: {width}Ã—{height}")
                metadata.append(f"ğŸ–¼ï¸ FormÃ¡t: {img.format}")
                if img.format == "JPEG":
                    quality = img.info.get('quality', 'NenÃ­ znÃ¡ma')
                    metadata.append(f"ğŸ” Kvalita: Odhad {quality}")
            with open(file_path, "rb") as f:
                tags = exifread.process_file(f)
                if tags:
                    metadata.append("ğŸ“‹ EXIF:")
                    for key, value in tags.items():
                        metadata.append(f"  {key}: {value}")
        
        elif file_path.endswith((".mp4", ".avi")):
            video = VideoFileClip(file_path)
            width, height = video.size
            duration = video.duration
            bitrate = os.path.getsize(file_path) * 8 / duration / 1000  # kbps
            metadata.append(f"ğŸ“ RozliÅ¡enÃ­: {width}Ã—{height}")
            metadata.append(f"â±ï¸ DÃ©lka: {duration:.2f} s")
            metadata.append(f"ğŸ“¹ Bitrate: {bitrate:.2f} kbps")
            metadata.append(f"ğŸï¸ FormÃ¡t: {Path(file_path).suffix}")
            video.close()
        
        elif file_path.endswith((".mp3", ".wav")):
            audio = mutagen.File(file_path)
            duration = audio.info.length if audio.info else 0
            bitrate = audio.info.bitrate / 1000 if hasattr(audio.info, "bitrate") else 0
            metadata.append(f"â±ï¸ DÃ©lka: {duration:.2f} s")
            metadata.append(f"ğŸµ Bitrate: {bitrate:.2f} kbps")
            metadata.append(f"ğŸ”Š FormÃ¡t: {Path(file_path).suffix}")
        
        return "\n".join(metadata) or "â“ Tenhle soubor je tajnÅ¯stkÃ¡Å™! Nic o nÄ›m nevÃ­me! ğŸ˜’"
    except Exception as e:
        return f"â— Metadata selhala: {e}. Ten soubor je asi z jinÃ© dimenze! ğŸŒŒ"

def generate_deepdanbooru_caption(image_path: str) -> str:
    """DeepDanbooru ti popÃ­Å¡e obrÃ¡zek, i kdyÅ¾ je slepej jako patron! ğŸ˜‚"""
    try:
        from deepdanbooru import DeepDanbooru
        model = DeepDanbooru()
        with Image.open(image_path) as img:
            tags = model.generate_tags(img)
        return f"ğŸ“œ DeepDanbooru Å™Ã­kÃ¡: {', '.join(tags)}"
    except Exception as e:
        return f"â— DeepDanbooru se zasekl: {e}. Asi mÃ¡ kocovinu! ğŸ˜µ"

def create_gui():
    """VytvoÅ™Ã­ GUI, co tÄ› rozsekÃ¡ jako pixely v blenderu! ğŸ˜ˆ"""
    Config.ensure_dirs()
    
    # Inicializace modelÅ¯ â€“ aÅ¥ se nikdo neflÃ¡kÃ¡!
    model_status = {
        "ImageProcessor": False,
        "FluxRunner": False,
        "SDXLRunner": False,
        "LipsyncEngine": False,
        "ForensicTools": False,
        "Segmenter": False,
        "VideoExporter": True,
        "AudioProcessor": False,
        "FaceSwapper": False,
        "Upscaler": False,
        "ExpressionEditor": False
    }

    # NOVÃ‰: AsynchronnÃ­ naÄÃ­tÃ¡nÃ­ modelÅ¯
    async def load_models_async():
        tasks = []
        try:
            processor = ImageProcessor()
            model_status["ImageProcessor"] = True
            logger.info("âœ… ImageProcessor je ready, pixely se tÅ™esou strachy!")
        except Exception as e:
            logger.error(f"âŒ ImageProcessor se rozsypal: {e}. Pixely v plÃ¡Äi!")
        
        try:
            flux_runner = FluxRunner()
            model_status["FluxRunner"] = True
            logger.info("âœ… FluxRunner je ready, umÄ›nÃ­ se rodÃ­!")
        except Exception as e:
            logger.error(f"âŒ FluxRunner selhal: {e}. UmÄ›nÃ­ je mrtvÃ©!")
        
        try:
            sdxl_runner = SDXLRunner()
            model_status["SDXLRunner"] = True
            logger.info("âœ… SDXLRunner je ready, generuje jako Å¡Ã­lenÃ½!")
        except Exception as e:
            logger.error(f"âŒ SDXLRunner selhal: {e}. Kreativita v prachu!")
        
        try:
            lipsync_engine = LipsyncEngine()
            model_status["LipsyncEngine"] = True
            logger.info("âœ… LipsyncEngine je ready, rty se synchronizujÃ­!")
        except Exception as e:
            logger.error(f"âŒ LipsyncEngine selhal: {e}. Rty ztuhly!")
        
        try:
            forensic_tools = ForensicTools(model_name="retinaface")
            model_status["ForensicTools"] = True
            logger.info("âœ… ForensicTools jsou ready, pravda se odhalÃ­!")
        except Exception as e:
            logger.error(f"âŒ ForensicTools selhaly: {e}. Pravda zÅ¯stane skrytÃ¡!")
        
        try:
            segmenter = Segmenter(use_grounding_dino=False)
            model_status["Segmenter"] = True
            logger.info("âœ… Segmenter je ready, pozadÃ­ jde pod nÅ¯Å¾!")
        except Exception as e:
            logger.error(f"âŒ Segmenter selhal: {e}. PozadÃ­ zÅ¯stane!")
        
        try:
            audio_processor = AudioProcessor()
            model_status["AudioProcessor"] = True
            logger.info("âœ… AudioProcessor je ready, zvuk se tÅ™Ã­dÃ­!")
        except Exception as e:
            logger.error(f"âŒ AudioProcessor selhal: {e}. Ticho pÅ™ed bouÅ™Ã­!")
        
        try:
            face_swapper = FaceSwapper()
            model_status["FaceSwapper"] = True
            logger.info("âœ… FaceSwapper je ready, obliÄeje se mÄ›nÃ­!")
        except Exception as e:
            logger.error(f"âŒ FaceSwapper selhal: {e}. ObliÄej zÅ¯stane tvÅ¯j!")
        
        try:
            upscaler = Upscaler()
            model_status["Upscaler"] = True
            logger.info("âœ… Upscaler je ready, pixely se zvÄ›tÅ¡ujÃ­!")
        except Exception as e:
            logger.error(f"âŒ Upscaler selhal: {e}. Pixely zÅ¯stanou malÃ½!")
        
        try:
            expression_editor = ExpressionEditor()
            model_status["ExpressionEditor"] = True
            logger.info("âœ… ExpressionEditor je ready, vÃ½razy se mÄ›nÃ­!")
        except Exception as e:
            logger.error(f"âŒ ExpressionEditor selhal: {e}. VÃ½raz zÅ¯stane kamennÃ½!")
            logger.warning("âš ï¸ FOMM modely chybÃ­? Mediapipe aspoÅˆ nezaspÃ­!")
        
        return processor, flux_runner, sdxl_runner, lipsync_engine, forensic_tools, segmenter, audio_processor, face_swapper, upscaler, expression_editor

    # SpustÃ­ asynchronnÃ­ naÄÃ­tÃ¡nÃ­ modelÅ¯
    processor, flux_runner, sdxl_runner, lipsync_engine, forensic_tools, segmenter, audio_processor, face_swapper, upscaler, expression_editor = asyncio.run(load_models_async())
    
    video_exporter = VideoExporter()
    logger.info("âœ… VideoExporter je ready, exportuje jako Å¡Ã©f!")

    # DynamickÃ½ dropdown pro expression modely
    expression_models = ["Mediapipe"]
    if ExpressionEditor.is_fomm_available():
        expression_models.append("FOMM")
    logger.info(f"ğŸ­ DostupnÃ© modely pro vÃ½razy: {expression_models}")

    # Historie a vÃ½stupnÃ­ sloÅ¾ka
    config = Config()
    history_dir = config.OUTPUT_DIR / "history"
    history_dir.mkdir(parents=True, exist_ok=True)

    # NOVÃ‰: VylepÅ¡enÃ© CSS s animacemi a responzivnÃ­m designem
    css = """
    .gradio-container { 
        background: linear-gradient(135deg, #ff6200, #000000);
        font-family: 'Arial', sans-serif; 
        color: #ffffff; 
    }
    h1 { 
        color: #ff6200; 
        text-align: center; 
        font-size: 2.5em; 
        text-shadow: 2px 2px 4px #000000; 
    }
    .tab-nav button { 
        background-color: #ff6200; 
        color: #000000; 
        border-radius: 8px; 
        padding: 12px; 
        font-weight: bold; 
        transition: background-color 0.3s ease, transform 0.2s; 
    }
    .tab-nav button:hover { 
        background-color: #e55b00; 
        transform: scale(1.05); 
    }
    .status-box { 
        background-color: rgba(0, 0, 0, 0.7); 
        padding: 15px; 
        border-radius: 8px; 
        margin: 10px 0; 
        color: #ff6200; 
        font-weight: bold; 
    }
    .history-gallery img { 
        border: 3px solid #ff6200; 
        border-radius: 8px; 
        transition: transform 0.2s; 
    }
    .history-gallery img:hover { 
        transform: scale(1.1); 
    }
    .gr-button-primary { 
        background-color: #ff6200 !important; 
        color: #000000 !important; 
        border: none !important; 
        transition: background-color 0.3s ease; 
    }
    .gr-button-primary:hover { 
        background-color: #e55b00 !important; 
    }
    .gr-button-secondary { 
        background-color: #333333 !important; 
        color: #ff6200 !important; 
        border: none !important; 
    }
    .gr-accordion { 
        background-color: rgba(255, 98, 0, 0.1); 
        border-radius: 8px; 
    }
    .progress-bar { 
        background: linear-gradient(90deg, #ff6200, #e55b00); 
        animation: pulse 2s infinite; 
    }
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.7; }
        100% { opacity: 1; }
    }
    @media (max-width: 768px) {
        .gradio-container { font-size: 0.9em; }
        .tab-nav button { padding: 8px; }
        .history-gallery img { width: 100%; }
    }
    .tooltip { 
        position: relative; 
    }
    .tooltip:hover:after { 
        content: attr(data-tooltip); 
        position: absolute; 
        bottom: 100%; 
        left: 50%; 
        transform: translateX(-50%); 
        background: #333; 
        color: #ff6200; 
        padding: 5px; 
        border-radius: 4px; 
        font-size: 0.8em; 
        white-space: nowrap; 
        z-index: 10; 
    }
    """

    with gr.Blocks(title="wAllICzech AI Studio 2025", css=css, theme=gr.themes.Soft()) as app:
        action_history = gr.State([])
        active_tab = gr.State("ObliÄej ğŸ˜Š")
        output_gallery = gr.State([])

        # NOVÃ‰: NÃ¡hodnÃ¡ hlÃ¡Å¡ka pÅ™i naÄÃ­tÃ¡nÃ­
        random_quotes = [
            "PÅ™ipravuji pixelovÃ© peklo, chvilku strpÄ›nÃ­! ğŸ”¥",
            "Å vejk by Å™ekl: 'Tohle bude poÅ™Ã¡dnej bordel!' ğŸ˜ˆ",
            "NaÄÃ­tÃ¡m modely, pixely uÅ¾ se tÅ™esou! ğŸ¨",
            "Pixely se Å™adÃ­ do zÃ¡stupu, Äekej chvilku! ğŸ’ª"
        ]
        gr.Markdown(
            f"# wAllICzech AI Studio 2025 ğŸ–¼ï¸ğŸ¨\n"
            f"{random_quotes[np.random.randint(0, len(random_quotes))]}\n"
            "Jedno vstupnÃ­ pole, vÅ¡echny funkce, metadata na oÄÃ­ch. "
            "PÅ™iprav se na AI, co tÄ› rozsekÃ¡ jako pixely v blenderu! ğŸ˜ˆ"
        )

        # StavovÃ½ box
        status = gr.Markdown("**Stav:** PÅ™ipraven k pixelovÃ© apokalypse! ğŸš€", elem_classes=["status-box"])
        # NOVÃ‰: AnimovanÃ½ progres bar
        progress_bar = gr.Slider(minimum=0, maximum=100, value=0, label="PrÅ¯bÄ›h (%)", interactive=False)

        with gr.Row():
            with gr.Column(scale=1, min_width=300):
                # VstupnÃ­ panel
                with gr.Accordion("VstupnÃ­ panel ğŸ“‚", open=True):
                    gr.Markdown("**Nahraj soubor, nebo Å vejk bude naÅ¡tvanÃ½! ğŸ˜ˆ**")
                    # NOVÃ‰: JednotnÃ© vstupnÃ­ pole
                    input_files = gr.File(
                        label="NahrÃ¡t soubory (obrÃ¡zky, videa, audio)",
                        file_count="multiple",
                        file_types=["image", "video", "audio"],
                        elem_classes=["tooltip"],
                        elem_id="input-files",
                        data_tooltip="Nahraj, nebo tÄ› poÅ¡lu do pixelovÃ½ho pekla! ğŸ˜ˆ"
                    )
                    source_selector = gr.Radio(
                        choices=["Soubory", "YouTube", "Kamera", "AdresÃ¡Å™"],
                        value="Soubory",
                        label="Zdroj",
                        info="Vyber, odkud chceÅ¡ bordel."
                    )
                    youtube_url = gr.Textbox(
                        label="YouTube URL",
                        visible=False,
                        info="VloÅ¾ odkaz, nebo se ztraÅ¥!",
                        elem_classes=["tooltip"],
                        data_tooltip="SprÃ¡vnÃ½ odkaz, nebo Å vejk ti dÃ¡ po Äuni! ğŸ˜¤"
                    )
                    # NOVÃ‰: Batch processing z adresÃ¡Å™e
                    batch_dir = gr.Textbox(
                        label="Cesta k adresÃ¡Å™i",
                        visible=False,
                        info="Zadej cestu k adresÃ¡Å™i pro hromadnÃ© zpracovÃ¡nÃ­."
                    )
                    metadata_display = gr.Textbox(
                        label="Metadata souboru",
                        interactive=False,
                        lines=5,
                        value="ğŸ“‹ Nahraj nÄ›co, nebo ti nic neÅ™eknu! ğŸ˜¤"
                    )
                    generate_caption_button = gr.Button("Generovat popis ğŸ“œ", variant="primary")
                    upload_button = gr.Button("NahrÃ¡t a zpracovat ğŸ“¤", variant="primary")
                    clear_button = gr.Button("VyÄistit vstupy ğŸ—‘ï¸", variant="secondary")

                # RychlÃ© akce
                with gr.Accordion("RychlÃ© akce âš¡", open=True):
                    quick_detect = gr.Button("Detekuj obliÄeje ğŸ”", variant="primary")
                    quick_upscale = gr.Button("RychlÃ© zvÄ›tÅ¡enÃ­ ğŸ“ˆ", variant="primary")
                    quick_segment = gr.Button("RychlÃ¡ segmentace âœ‚ï¸", variant="primary")

                # Stav modelÅ¯
                with gr.Accordion("Stav modelÅ¯ ğŸ› ï¸", open=False):
                    status_textbox = gr.Textbox(
                        value="\n".join([f"{k}: {'âœ… NaÄten' if v else 'âŒ Selhal'}" for k, v in model_status.items()]),
                        label="Stav inicializace modelÅ¯",
                        interactive=False,
                        lines=10
                    )

            with gr.Column(scale=3, min_width=800):
                # NÃ¡stroje
                gr.Markdown("## NÃ¡stroje ğŸ› ï¸")
                with gr.Tabs() as tabs:
                    with gr.Tab(label="ObliÄej ğŸ˜Š", id="face"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Detekce, vÃ½mÄ›na obliÄejÅ¯, Ãºprava vÃ½razÅ¯**")
                                face_swap_target = gr.File(
                                    label="CÃ­lovÃ½ obliÄej pro vÃ½mÄ›nu",
                                    file_types=["image"],
                                    elem_classes=["tooltip"],
                                    data_tooltip="Nahraj obliÄej, nebo zÅ¯staneÅ¡ sÃ¡m sebou! ğŸ˜"
                                )
                                expression_slider = gr.Slider(
                                    minimum=-1.0, maximum=1.0, value=0.0,
                                    label="ÃšsmÄ›v ğŸ˜„",
                                    info="Uprav vÃ½raz (-1 = pohÅ™eb, 1 = karneval)."
                                )
                                expression_model = gr.Dropdown(
                                    choices=expression_models,
                                    value="Mediapipe",
                                    label="Model vÃ½razÅ¯",
                                    info="Vyber, kdo ti zmÄ›nÃ­ ksicht."
                                )
                                with gr.Row():
                                    detect_face_button = gr.Button("Detekuj obliÄeje ğŸ”", variant="primary")
                                    face_swap_button = gr.Button("VymÄ›nit obliÄej ğŸ”„", variant="primary")
                                    apply_expression_button = gr.Button("Aplikovat vÃ½raz âœ¨", variant="primary")
                                toggle_camera = gr.Button("Zapnout/vypnout kameru ğŸ“·", variant="secondary")
                            with gr.Column(scale=1):
                                face_output = gr.Image(label="VÃ½sledek", type="filepath")

                    with gr.Tab(label="Lipsync ğŸ¤", id="lipsync"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Synchronizace rtÅ¯, aÅ¥ mluvÃ­Å¡ jako profÃ­k!**")
                                lipsync_mode = gr.Dropdown(
                                    choices=["AutomatickÃ½", "ManuÃ¡lnÃ­ korekce", "HybridnÃ­"],
                                    value="AutomatickÃ½",
                                    label="ReÅ¾im lipsyncu",
                                    info="Vyber, jak moc chceÅ¡ Å™Ã­dit chaos."
                                )
                                # NOVÃ‰: InteraktivnÃ­ phoneme timeline
                                phoneme_timeline = gr.Plot(
                                    label="ÄŒasovÃ¡ osa fonÃ©mÅ¯ â³",
                                    visible=False,
                                    info="Uprav fonÃ©my pÅ™etaÅ¾enÃ­m bodÅ¯."
                                )
                                lipsync_button = gr.Button("Spustit lipsync ğŸ¬", variant="primary")
                            with gr.Column(scale=1):
                                lipsync_output = gr.Video(label="VÃ½sledek")

                    with gr.Tab(label="ZvÄ›tÅ¡enÃ­ ğŸ”", id="upscale"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**ZvÄ›tÅ¡Ã­me tvÃ© pixely, aÅ¥ zÃ¡vidÃ­ Hubble!**")
                                upscale_model = gr.Dropdown(
                                    choices=["RealESRGAN_x4plus", "4x-UltraSharp"],
                                    value="RealESRGAN_x4plus",
                                    label="Model zvÄ›tÅ¡enÃ­",
                                    info="Vyber, co ti zvÄ›tÅ¡Ã­ ego."
                                )
                                upscale_factor = gr.Slider(
                                    minimum=1, maximum=4, value=2, step=1,
                                    label="Faktor zvÄ›tÅ¡enÃ­",
                                    info="2 = 2x vÄ›tÅ¡Ã­, logika!"
                                )
                                # NOVÃ‰: Batch processing
                                batch_upscale = gr.Checkbox(
                                    label="Zpracovat vÅ¡echny soubory",
                                    value=False,
                                    info="ZaÅ¡krtnÄ›te pro hromadnÃ© zvÄ›tÅ¡enÃ­."
                                )
                                upscale_button = gr.Button("ZvÄ›tÅ¡it obrÃ¡zek ğŸ“ˆ", variant="primary")
                            with gr.Column(scale=1):
                                upscale_output = gr.Image(label="VÃ½sledek", type="filepath")

                    with gr.Tab(label="Segmentace âœ‚ï¸", id="segment"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Rozsekej pozadÃ­ jako profÃ­k!**")
                                segment_mode = gr.Dropdown(
                                    choices=["Odstranit pozadÃ­", "Rozmazat pozadÃ­"],
                                    value="Odstranit pozadÃ­",
                                    label="ReÅ¾im segmentace",
                                    info="Co s tÃ­m pozadÃ­m provedeme?"
                                )
                                segment_prompt = gr.Textbox(
                                    label="TextovÃ½ popis",
                                    placeholder="napÅ™. 'ÄlovÄ›k'",
                                    info="Co mÃ¡me vyÅ™Ã­znout?"
                                )
                                segment_button = gr.Button("Segmentovat âœ‚ï¸", variant="primary")
                            with gr.Column(scale=1):
                                segment_output = gr.Image(label="VÃ½sledek", type="filepath")

                    with gr.Tab(label="Zvuk ğŸµ", id="audio"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Separuj a pÅ™episuj zvuk jako Å¡Ã©f!**")
                                stem_selector = gr.CheckboxGroup(
                                    choices=["vokÃ¡ly", "bicÃ­", "basa", "ostatnÃ­"],
                                    label="Vyber stopy pro separaci",
                                    value=["vokÃ¡ly", "bicÃ­", "basa", "ostatnÃ­"],
                                    info="Co chceÅ¡ oddÄ›lit?"
                                )
                                # NOVÃ‰: Live nÃ¡hled zvukovÃ½ch efektÅ¯
                                audio_effect = gr.Dropdown(
                                    choices=["Å½Ã¡dnÃ½", "Echo", "Reverb", "Pitch Shift"],
                                    value="Å½Ã¡dnÃ½",
                                    label="PÅ™idat efekt",
                                    info="Vyber efekt pro live nÃ¡hled."
                                )
                                with gr.Row():
                                    separate_stems_button = gr.Button("Separovat stopy ğŸ™ï¸", variant="primary")
                                    transcribe_button = gr.Button("PÅ™epsat zvuk ğŸ“œ", variant="primary")
                                    apply_effect_button = gr.Button("Aplikovat efekt ğŸµ", variant="primary")
                            with gr.Column(scale=1):
                                transcription_output = gr.Textbox(
                                    label="PÅ™epis zvuku",
                                    interactive=False,
                                    lines=5
                                )
                                audio_output = gr.Audio(label="NÃ¡hled efektu")

                    with gr.Tab(label="ForenznÃ­ analÃ½za ğŸ”", id="forensic"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**OdhalÃ­me kaÅ¾dÃ½ Å¡patnÃ½ pixel!**")
                                # NOVÃ‰: PorovnÃ¡nÃ­ dvou obrÃ¡zkÅ¯
                                compare_image = gr.File(
                                    label="DruhÃ½ obrÃ¡zek pro porovnÃ¡nÃ­",
                                    file_types=["image"],
                                    elem_classes=["tooltip"],
                                    data_tooltip="Nahraj druhÃ½ obrÃ¡zek pro ELA/JPEG analÃ½zu."
                                )
                                with gr.Row():
                                    forensic_button = gr.Button("Analyzovat JPEG artefakty ğŸ“Š", variant="primary")
                                    ela_button = gr.Button("Error Level Analysis ğŸ”", variant="primary")
                                    deepfake_button = gr.Button("Detekovat deepfake ğŸ•µï¸â€â™‚ï¸", variant="primary")
                                    exif_button = gr.Button("Extrahovat EXIF metadata ğŸ“‹", variant="primary")
                                    report_button = gr.Button("Vygenerovat PDF zprÃ¡vu ğŸ“œ", variant="primary")
                                # NOVÃ‰: Deepfake skÃ³re graf
                                deepfake_plot = gr.Plot(label="Deepfake skÃ³re")
                            with gr.Column(scale=1):
                                exif_output = gr.Textbox(
                                    label="EXIF metadata",
                                    interactive=False,
                                    lines=5
                                )
                                forensic_output = gr.Image(label="VÃ½sledek analÃ½zy", type="filepath")

                    with gr.Tab(label="Text na obrÃ¡zek ğŸ¨", id="text2image"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Generuj umÄ›nÃ­, aÅ¥ zÃ¡vidÃ­ Da Vinci!**")
                                sdxl_prompt = gr.Textbox(
                                    label="Prompt",
                                    value=config.config["models"]["diffusers"]["sdxl"]["default_prompt"],
                                    placeholder="Zadej popis, napÅ™. 'KyberpunkovÃ© mÄ›sto'"
                                )
                                sdxl_negative_prompt = gr.Textbox(
                                    label="NegativnÃ­ prompt",
                                    value=config.config["models"]["diffusers"]["sdxl"]["default_negative_prompt"],
                                    placeholder="Co nechceÅ¡, napÅ™. 'rozmazanÃ©'"
                                )
                                sdxl_steps = gr.Slider(
                                    10, 100, value=config.config["models"]["diffusers"]["sdxl"]["default_steps"],
                                    label="PoÄet krokÅ¯"
                                )
                                sdxl_guidance = gr.Slider(
                                    1.0, 15.0, value=config.config["models"]["diffusers"]["sdxl"]["default_guidance_scale"],
                                    label="Guidance Scale"
                                )
                                sdxl_strength = gr.Slider(
                                    0.1, 1.0, value=config.config["models"]["diffusers"]["sdxl"]["default_strength"],
                                    label="SÃ­la (img2img)"
                                )
                                with gr.Row():
                                    sdxl_text2img_button = gr.Button("Generovat âœ¨", variant="primary")
                                    sdxl_img2img_button = gr.Button("Stylizovat vstup ğŸ¨", variant="secondary")
                            with gr.Column(scale=1):
                                sdxl_output = gr.Image(label="VÃ½sledek", type="pil")
                                sdxl_save_button = gr.Button("UloÅ¾it do historie ğŸ’¾", variant="secondary")

                    with gr.Tab(label="Flux stylizace ğŸ¨", id="flux"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Flux.1-dev â€“ umÄ›nÃ­ na steroidech!**")
                                flux_prompt = gr.Textbox(
                                    label="Prompt",
                                    value=config.config["models"]["diffusers"]["flux"]["default_prompt"],
                                    placeholder="Zadej popis, napÅ™. 'KrÃ¡snÃ½ les'"
                                )
                                flux_negative_prompt = gr.Textbox(
                                    label="NegativnÃ­ prompt",
                                    value=config.config["models"]["diffusers"]["flux"]["default_negative_prompt"],
                                    placeholder="Co nechceÅ¡, napÅ™. 'rozmazanÃ©'"
                                )
                                flux_steps = gr.Slider(
                                    10, 100, value=config.config["models"]["diffusers"]["flux"]["default_steps"],
                                    label="PoÄet krokÅ¯"
                                )
                                flux_guidance = gr.Slider(
                                    1.0, 15.0, value=config.config["models"]["diffusers"]["flux"]["default_guidance_scale"],
                                    label="Guidance Scale"
                                )
                                flux_strength = gr.Slider(
                                    0.1, 1.0, value=config.config["models"]["diffusers"]["flux"]["default_strength"],
                                    label="SÃ­la (img2img)"
                                )
                                flux_sampler = gr.Dropdown(
                                    choices=["Euler", "DDIM", "DPM++ 2M Karras", "Euler Ancestral"],
                                    value="Euler",
                                    label="Sampler"
                                )
                                flux_lora_weight = gr.Slider(
                                    minimum=0.0, maximum=1.0, value=0.8, step=0.05,
                                    label="VÃ¡ha LoRA"
                                )
                                flux_width = gr.Slider(
                                    minimum=256, maximum=2048, value=512, step=8,
                                    label="Å Ã­Å™ka vÃ½stupu"
                                )
                                flux_height = gr.Slider(
                                    minimum=256, maximum=2048, value=512, step=8,
                                    label="VÃ½Å¡ka vÃ½stupu"
                                )
                                with gr.Row():
                                    flux_text2img_button = gr.Button("Generovat âœ¨", variant="primary")
                                    flux_img2img_button = gr.Button("Stylizovat vstup ğŸ¨", variant="secondary")
                            with gr.Column(scale=1):
                                flux_output = gr.Image(label="VÃ½sledek", type="pil")
                                flux_save_button = gr.Button("UloÅ¾it do historie ğŸ’¾", variant="secondary")

                # NÃ¡hledovÃ½ panel
                gr.Markdown("## NÃ¡hledovÃ½ panel ğŸ–¥ï¸")
                with gr.Tabs():
                    with gr.Tab("JednotlivÃ½ nÃ¡hled"):
                        preview_output = gr.Image(label="VÃ½stupnÃ­ nÃ¡hled", interactive=False, height=600)
                    with gr.Tab("Galerie vÃ½stupÅ¯"):
                        gallery_output = gr.Gallery(label="VÅ¡echny vÃ½stupy", columns=3, height=600)

                # Export a sprÃ¡va
                with gr.Accordion("Export a sprÃ¡va ğŸ’¾", open=False):
                    export_format = gr.Dropdown(
                        choices=["MP4", "GIF", "PNG sekvence"],
                        value="MP4",
                        label="FormÃ¡t exportu"
                    )
                    export_fps = gr.Slider(
                        minimum=1, maximum=60, value=30, step=1,
                        label="FPS"
                    )
                    export_name = gr.Textbox(
                        label="NÃ¡zev vÃ½stupu",
                        placeholder="napÅ™. output.mp4"
                    )
                    # NOVÃ‰: Export historie do CSV
                    export_history_csv = gr.Button("Exportovat historii jako CSV ğŸ“Š", variant="secondary")
                    with gr.Row():
                        export_button = gr.Button("Exportovat vÃ½sledek ğŸ“¤", variant="primary")
                        save_project_button = gr.Button("UloÅ¾it projekt ğŸ’¾", variant="primary")
                        load_project_button = gr.Button("NaÄÃ­st projekt ğŸ“‚", variant="primary")
                        undo_button = gr.Button("VrÃ¡tit akci â†©ï¸", variant="secondary")

                # Historie akcÃ­
                with gr.Accordion("Historie akcÃ­ ğŸ“œ", open=False):
                    # NOVÃ‰: FiltrovÃ¡nÃ­ historie
                    history_filter = gr.Dropdown(
                        choices=["VÅ¡e", "Lipsync", "Upscale", "Segmentace", "Zvuk", "ForenznÃ­", "SDXL", "Flux"],
                        value="VÅ¡e",
                        label="Filtrovat akce"
                    )
                    history_display = gr.Textbox(
                        label="ProvedenÃ© akce",
                        interactive=False,
                        lines=5
                    )
                    show_history_button = gr.Button("Zobrazit historii â†©ï¸", variant="secondary")
                    history_gallery = gr.Gallery(
                        label="VygenerovanÃ© obrÃ¡zky",
                        value=[str(p) for p in history_dir.glob("*.png")],
                        columns=4,
                        height="auto",
                        preview=True
                    )
                    refresh_history_button = gr.Button("Obnovit historii ğŸ”„", variant="secondary")

        # Funkce pro aktualizaci GUI
        async def update_active_tab(tab_id: Optional[str] = None) -> str:
            tab_names = {
                "face": "ObliÄej ï¿½åœ°ä¸‹",
                "lipsync": "Lipsync ğŸ¤",
                "upscale": "ZvÄ›tÅ¡enÃ­ ğŸ”",
                "segment": "Segmentace âœ‚ï¸",
                "audio": "Zvuk ğŸµ",
                "forensic": "ForenznÃ­ analÃ½za ğŸ”",
                "text2image": "Text na obrÃ¡zek ğŸ¨",
                "flux": "Flux stylizace ğŸ¨"
            }
            return tab_names.get(tab_id, "ObliÄej ğŸ˜Š")

        def update_source_selector(source: str):
            return (
                gr.update(visible=source == "YouTube"),
                gr.update(visible=source == "AdresÃ¡Å™")
            )

        # NOVÃ‰: Phoneme timeline
        def update_phoneme_timeline(mode: str, audio_path: str):
            if mode not in ["ManuÃ¡lnÃ­ korekce", "HybridnÃ­"] or not audio_path:
                return gr.update(visible=False, value=None)
            try:
                # Simulace phoneme dat (v reÃ¡lu bys pouÅ¾il audio_processor.analyze_phonemes)
                times = np.linspace(0, 5, 10)
                phonemes = ["aa", "ee", "oo", "sil", "aa", "ee", "oo", "sil", "aa", "ee"]
                df = pd.DataFrame({"Time (s)": times, "Phoneme": phonemes})
                fig = px.scatter(df, x="Time (s)", y="Phoneme", title="Phoneme Timeline")
                return gr.update(visible=True, value=fig)
            except Exception as e:
                logger.error(f"âŒ Phoneme timeline selhal: {e}")
                return gr.update(visible=False, value=None)

        def save_to_history(image: Image.Image, model: str, prompt: str) -> str:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_path = history_dir / f"{model}_{timestamp}_{prompt[:20].replace(' ', '_')}.png"
            image.save(output_path)
            logger.info(f"ğŸ“œ ObrÃ¡zek uloÅ¾en do historie: {output_path}")
            return str(output_path)

        def get_history_images():
            return [str(p) for p in history_dir.glob("*.png")]

        # NOVÃ‰: Export historie do CSV
        def export_history_to_csv(history: List[Dict]):
            if not history:
                status.value = "**Stav:** Historie je prÃ¡zdnÃ¡, nic jsi nedÄ›lal! ğŸ“œ"
                return "â— Historie je prÃ¡zdnÃ¡!"
            df = pd.DataFrame(history)
            output_path = config.OUTPUT_DIR / f"history_{time.strftime('%Y%m%d_%H%M%S')}.csv"
            df.to_csv(output_path, index=False)
            logger.info(f"ğŸ“Š Historie exportovÃ¡na: {output_path}")
            return f"âœ… Historie exportovÃ¡na: {output_path}"

        async def upload_and_preview(files: List[str], source: str, youtube_url: str, batch_dir: str, 
                                   history: List[Dict], stem_selector: List[str], gallery: List[str]):
            progress_bar.value = 10
            file_path = None
            if source == "Soubory" and files:
                file_path = files[0]  # PrvnÃ­ soubor pro nÃ¡hled
            elif source == "YouTube" and youtube_url:
                try:
                    progress_bar.value = 30
                    output_path = config.OUTPUT_DIR / get_next_output_filename("mp4")
                    download_youtube(youtube_url, str(output_path))
                    history.append({"action": "youtube_stÃ¡hnout", "output": str(output_path)})
                    gallery.append(str(output_path))
                    progress_bar.value = 50
                    audio_path = config.OUTPUT_DIR / get_next_output_filename("wav")
                    video = VideoFileClip(str(output_path))
                    video.audio.write_audiofile(str(audio_path))
                    video.close()
                    progress_bar.value = 70
                    stem_result = audio_processor.separate_audio_demucs(str(audio_path), stem_selector)
                    history.append({"action": "separovat_stopy", "output": stem_result["output_paths"]})
                    progress_bar.value = 90
                    transcribe_result = audio_processor.transcribe_audio(str(audio_path))
                    history.append({"action": "pÅ™epsat_zvuk", "output": transcribe_result["output_path"]})
                    status.value = "**Stav:** YouTube video staÅ¾eno! ğŸ‰"
                    return None, gallery, f"âœ… YouTube video staÅ¾eno: {output_path}", history, 100, audio_path, transcribe_result["transcription"], get_file_metadata(str(output_path))
                except Exception as e:
                    status.value = "**Stav:** YouTube se zasekl! ğŸ˜µ"
                    return None, [], f"â— Chyba: {e}", history, 0, None, "", "â— YouTube selhal!"
            elif source == "Kamera":
                try:
                    progress_bar.value = 50
                    cap = cv2.VideoCapture(0)
                    if not cap.isOpened():
                        status.value = "**Stav:** Kamera je mimo! ğŸ“·"
                        raise ValueError("Kamera zaspala!")
                    ret, frame = cap.read()
                    cap.release()
                    if ret:
                        output_path = config.OUTPUT_DIR / get_next_output_filename("jpg")
                        cv2.imwrite(str(output_path), frame)
                        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        history.append({"action": "kamera_snÃ­mek", "output": str(output_path)})
                        gallery.append(str(output_path))
                        status.value = "**Stav:** SnÃ­mek uloÅ¾en! ğŸ‰"
                        return img, gallery, f"âœ… SnÃ­mek uloÅ¾en: {output_path}", history, 100, None, "", get_file_metadata(str(output_path))
                    status.value = "**Stav:** Kamera selhala! ğŸ˜µ"
                    return None, [], "â— Kamera selhala!", history, 0, None, "", "â— Kamera je mimo!"
                except Exception as e:
                    status.value = "**Stav:** Kamera je v hÃ¡ji! ğŸ˜µ"
                    return None, [], f"â— Chyba: {e}", history, 0, None, "", "â— Kamera zaspala!"
            elif source == "AdresÃ¡Å™" and batch_dir:
                try:
                    batch_path = Path(batch_dir)
                    if not batch_path.is_dir():
                        status.value = "**Stav:** AdresÃ¡Å™ neexistuje! ğŸ“‚"
                        return None, [], "â— AdresÃ¡Å™ neexistuje!", history, 0, None, "", "â— Å patnÃ¡ cesta!"
                    files = [str(p) for p in batch_path.glob("*") if p.suffix in [".jpg", ".png", ".mp4", ".avi", ".mp3", ".wav"]]
                    if not files:
                        status.value = "**Stav:** AdresÃ¡Å™ je prÃ¡zdnÃ½! ğŸ“‚"
                        return None, [], "â— Å½Ã¡dnÃ© soubory!", history, 0, None, "", "â— PrÃ¡zdnÃ½ adresÃ¡Å™!"
                    file_path = files[0]
                    history.append({"action": "nahrÃ¡t_adresÃ¡Å™", "output": batch_dir})
                    gallery.extend(files)
                    status.value = "**Stav:** AdresÃ¡Å™ nahrÃ¡n! ğŸ‰"
                    return None, gallery, f"âœ… NahrÃ¡n adresÃ¡Å™: {batch_dir}", history, 100, None, "", get_file_metadata(file_path)
                except Exception as e:
                    status.value = "**Stav:** AdresÃ¡Å™ selhal! ğŸ˜µ"
                    return None, [], f"â— Chyba: {e}", history, 0, None, "", "â— AdresÃ¡Å™ je mimo!"
            
            if file_path and Path(file_path).exists():
                history.append({"action": f"nahrÃ¡t_{source.lower()}", "output": file_path})
                gallery.append(file_path)
                status.value = f"**Stav:** {source} nahrÃ¡n! ğŸ‰"
                return None, gallery, f"âœ… {source} nahrÃ¡n!", history, 100, None, "", get_file_metadata(file_path)
            status.value = "**Stav:** Nic jsi nenahrÃ¡l, trollÃ­Å¡ mÄ›? ğŸ˜¤"
            return None, [], "â— Nahraj nÄ›co!", history, 0, None, "", "â— Å½Ã¡dnÃ½ soubor!"

        def clear_inputs(history: List[Dict], gallery: List[str]):
            history.append({"action": "vyÄistit_vstupy", "output": None})
            gallery.clear()
            status.value = "**Stav:** VÅ¡e vyÄiÅ¡tÄ›no, jako po vÃ½buchu! ğŸ—‘ï¸"
            return None, [], None, None, [], "âœ… VÅ¡e vyÄiÅ¡tÄ›no!", history, 100, None, "", "ğŸ“‹ Å½Ã¡dnÃ¡ metadata, nahraj nÄ›co!"

        async def detect_face(image_path: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku to nepÅ¯jde, gÃ©nius! ğŸ“·"
                return None, [], "â— Nahraj obrÃ¡zek!", history, 0
            progress_bar.value = 50
            try:
                img = processor.load_image(image_path)
                faces = processor.detect_faces(img)
                if faces:
                    img_with_faces = processor.draw_faces(img, faces)
                    output_path = config.OUTPUT_DIR / get_next_output_filename("jpg")
                    cv2.imwrite(str(output_path), cv2.cvtColor(img_with_faces, cv2.COLOR_RGB2BGR))
                    history.append({"action": "detekovat_obliÄej", "output": output_path})
                    gallery.append(output_path)
                    status.value = f"**Stav:** Nalezeno {len(faces)} obliÄejÅ¯! ğŸ‰"
                    return output_path, gallery, f"âœ… Nalezeno {len(faces)} obliÄejÅ¯!", history, 100
                status.value = "**Stav:** Å½Ã¡dnÃ© obliÄeje, co to je, duch? ğŸ‘»"
                return img, gallery, "â— Å½Ã¡dnÃ© obliÄeje!", history, 100
            except Exception as e:
                status.value = "**Stav:** Detekce obliÄejÅ¯ se podÄ›lala! ğŸ˜µ"
                return None, [], f"â— Chyba: {e}", history, 0

        async def run_face_swap(image_path: str, target_image: str, history: List[Dict], gallery: List[str]):
            if not image_path or not target_image or not Path(image_path).exists() or not Path(target_image).exists():
                status.value = "**Stav:** ChybÃ­ obrÃ¡zky, to jako vÃ¡Å¾nÄ›? ğŸ“·"
                return None, [], "â— Nahraj oba obrÃ¡zky!", history, 0
            progress_bar.value = 50
            try:
                result = face_swapper.swap_face(image_path, target_image)
                output_path = config.OUTPUT_DIR / get_next_output_filename("jpg")
                cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                history.append({"action": "vymÄ›nit_obliÄej", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** ObliÄej vymÄ›nÄ›n, vypadÃ¡Å¡ jako celebrita! ğŸ‰"
                return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** VÃ½mÄ›na obliÄejÅ¯ se zasekla! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", history, 0

        async def apply_expression(image_path: str, expression_value: float, expression_model: str, 
                                 history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku Å¾Ã¡dnÃ½ vÃ½raz, logika! ğŸ“·"
                return None, [], "â— Nahraj obrÃ¡zek!", history, 0
            progress_bar.value = 50
            try:
                result = expression_editor.apply_expression(image_path, expression_value, expression_model, line_color=(0, 255, 0))
                output_path = config.OUTPUT_DIR / get_next_output_filename("jpg")
                cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                history.append({"action": "aplikovat_vÃ½raz", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** VÃ½raz aplikovÃ¡n, zelenÃ¡ ÄÃ¡ra rulez! ğŸ‰"
                return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** VÃ½raz se neaplikoval, nÄ›co smrdÃ­! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", history, 0

        async def toggle_camera_stream():
            status.value = "**Stav:** Kamera se budÃ­! ğŸ“·"
            return gr.update(visible=True)

        async def run_lipsync(video_path: str, audio_path: str, mode: str, history: List[Dict], gallery: List[str]):
            if not video_path or not audio_path or not Path(video_path).exists() or not Path(audio_path).exists():
                status.value = "**Stav:** Video nebo zvuk chybÃ­, to je fiasko! ğŸ“¹ğŸµ"
                return None, [], "â— Nahraj video a zvuk!", history, 0
            progress_bar.value = 50
            try:
                normalized_audio = audio_processor.normalize_audio(audio_path)
                output_path = config.OUTPUT_DIR / get_next_output_filename("mp4")
                lipsync_engine.generate_lipsync(video_path, normalized_audio, output_path)
                history.append({"action": "lipsync", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** Lipsync hotov, mluvÃ­Å¡ jak profÃ­k! ğŸ‰"
                return output_path, gallery, "âœ… Lipsync dokonÄen!", history, 100
            except Exception as e:
                status.value = "**Stav:** Lipsync se zasekl! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", history, 0

        async def run_upscale(image_path: str, model: str, factor: int, batch_mode: bool, files: List[str], history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku nezvÄ›tÅ¡Ã­Å¡ nic, gÃ©nius! ğŸ“·"
                return None, [], "â— Nahraj obrÃ¡zek!", history, 0
            progress_bar.value = 50
            try:
                if batch_mode and files:
                    output_paths = []
                    for img_path in files:
                        if Path(img_path).suffix in [".jpg", ".png"]:
                            result = upscaler.upscale_image(img_path, model_name=model, scale=factor, device="cuda" if torch.cuda.is_available() else "cpu")
                            output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                            cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                            output_paths.append(output_path)
                            gallery.append(output_path)
                    history.append({"action": "batch_zvÄ›tÅ¡it", "output": output_paths})
                    status.value = "**Stav:** HromadnÃ© zvÄ›tÅ¡enÃ­ dokonÄeno! ğŸ‰"
                    return output_paths[0], gallery, "âœ… Batch zvÄ›tÅ¡enÃ­ hotovo!", history, 100
                else:
                    result = upscaler.upscale_image(image_path, model_name=model, scale=factor, device="cuda" if torch.cuda.is_available() else "cpu")
                    output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                    cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                    history.append({"action": "zvÄ›tÅ¡it", "output": output_path})
                    gallery.append(output_path)
                    status.value = "**Stav:** ZvÄ›tÅ¡eno, pixely v extÃ¡zi! ğŸ‰"
                    return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** ZvÄ›tÅ¡enÃ­ se podÄ›lalo, asi mÃ¡Å¡ malou GPU! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", history, 0

        async def run_segmentation(image_path: str, mode: str, prompt: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists() or not prompt:
                status.value = "**Stav:** ObrÃ¡zek nebo popis chybÃ­, to je trapas! ğŸ“·"
                return None, [], "â— Nahraj obrÃ¡zek a popis!", history, 0
            progress_bar.value = 50
            try:
                if mode == "Odstranit pozadÃ­":
                    result = segmenter.text_guided_segmentation(image_path, prompt)
                    output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                    cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                    history.append({"action": "segmentace", "output": output_path})
                    gallery.append(output_path)
                    status.value = "**Stav:** PozadÃ­ pryÄ, ÄistÃ½ styl! ğŸ‰"
                    return output_path, gallery, result["message"], history, 100
                elif mode == "Rozmazat pozadÃ­":
                    output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                    segmenter.blur_background(image_path, output_path, blur_strength=21)
                    history.append({"action": "rozmazat_pozadÃ­", "output": output_path})
                    gallery.append(output_path)
                    status.value = "**Stav:** PozadÃ­ rozmazanÃ½, jako po tÅ™ech pivech! ğŸ‰"
                    return output_path, gallery, "âœ… RozmazÃ¡nÃ­ dokonÄeno!", history, 100
            except Exception as e:
                status.value = "**Stav:** Segmentace se zasekla! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", history, 0

        async def separate_stems(audio_path: str, stems: List[str], history: List[Dict], gallery: List[str]):
            if not audio_path or not Path(audio_path).exists() or not stems:
                status.value = "**Stav:** Zvuk nebo stopy chybÃ­, to je ticho! ğŸµ"
                return None, [], "", "â— Nahraj zvuk a stopy!", history, 0
            progress_bar.value = 50
            try:
                result = audio_processor.separate_audio_demucs(audio_path, stems)
                output_paths = []
                for stem, path in result["output_paths"].items():
                    new_path = config.OUTPUT_DIR / get_next_output_filename("wav")
                    os.rename(path, new_path)
                    output_paths.append(str(new_path))
                history.append({"action": "separovat_stopy", "output": output_paths})
                status.value = "**Stav:** Stopy separovÃ¡ny, vÅ¡e hraje! ğŸ‰"
                return None, [], result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** Separace stop selhala, vÅ¡e je jeden chaos! ğŸ˜µ"
                return None, [], f"â— Chyba: {e}", history, 0

        async def apply_audio_effect(audio_path: str, effect: str, history: List[Dict], gallery: List[str]):
            if not audio_path or not Path(audio_path).exists():
                status.value = "**Stav:** Bez zvuku Å¾Ã¡dnÃ½ efekt, logika! ğŸµ"
                return None, [], "", history, 0
            progress_bar.value = 50
            try:
                # Simulace aplikace efektu (v reÃ¡lu bys pouÅ¾il audio_processor.apply_effect)
                output_path = config.OUTPUT_DIR / get_next_output_filename("wav")
                audio_processor.normalize_audio(audio_path)  # Placeholder
                history.append({"action": f"aplikovat_efekt_{effect.lower()}", "output": output_path})
                status.value = f"**Stav:** Efekt {effect} aplikovÃ¡n, znÃ­ to jak z Grammy! ğŸ‰"
                return output_path, [], "âœ… Efekt aplikovÃ¡n!", history, 100
            except Exception as e:
                status.value = "**Stav:** Efekt selhal, asi Å¡patnÃ½ mixpult! ğŸ˜µ"
                return None, [], f"â— Chyba: {e}", history, 0

        async def transcribe_audio(audio_path: str, history: List[Dict], gallery: List[str]):
            if not audio_path or not Path(audio_path).exists():
                status.value = "**Stav:** Bez zvuku Å¾Ã¡dnÃ½ pÅ™epis, logika! ğŸµ"
                return None, [], "", "â— Nahraj zvuk!", history, 0
            progress_bar.value = 50
            try:
                result = audio_processor.transcribe_audio(audio_path)
                history.append({"action": "pÅ™epsat_zvuk", "output": result["output_path"]})
                status.value = "**Stav:** PÅ™epis hotov, text je tvÅ¯j! ğŸ‰"
                return None, [], result["transcription"], history, 100
            except Exception as e:
                status.value = "**Stav:** PÅ™epis selhal, asi Å¡patnÃ½ mikrofon! ğŸ˜µ"
                return None, [], f"â— Chyba: {e}", history, 0

        async def run_artifact_analysis(image_path: str, compare_image: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku Å¾Ã¡dnÃ¡ analÃ½za, Sherlocku! ğŸ“·"
                return None, [], "â— Nahraj obrÃ¡zek!", history, 0
            progress_bar.value = 50
            try:
                result = forensic_tools.analyze_jpeg_artifacts(image_path)
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                history.append({"action": "analyzovat_artefakty", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** Artefakty analyzovÃ¡ny, jsi detektiv! ğŸ‰"
                return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** AnalÃ½za se zasekla! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", history, 0

        async def run_ela_analysis(image_path: str, compare_image: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku Å¾Ã¡dnÃ¡ ELA, Sherlocku! ğŸ“·"
                return None, [], "â— Nahraj obrÃ¡zek!", history, 0
            progress_bar.value = 50
            try:
                result = forensic_tools.error_level_analysis(image_path)
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                history.append({"action": "ela_analÃ½za", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** ELA hotovÃ¡, manipulace odhalena! ğŸ‰"
                return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** ELA se zasekla! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", history, 0

        async def run_deepfake_detection(image_path: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku Å¾Ã¡dnÃ½ deepfake lov, Sherlocku! ğŸ“·"
                return None, [], None, "â— Nahraj obrÃ¡zek!", history, 0
            progress_bar.value = 50
            try:
                result = forensic_tools.detect_deepfake(image_path)
                # NOVÃ‰: Deepfake skÃ³re graf
                score = result.get("score", 0.5)
                df = pd.DataFrame({"Kategorie": ["Deepfake pravdÄ›podobnost"], "SkÃ³re": [score]})
                fig = px.bar(df, x="Kategorie", y="SkÃ³re", title="Deepfake SkÃ³re", range_y=[0, 1])
                history.append({"action": "detekovat_deepfake", "output": None})
                status.value = "**Stav:** Deepfake analÃ½za hotovÃ¡, pravda venku! ğŸ‰"
                return None, gallery, fig, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** Deepfake detekce selhala! ğŸ˜µ"
                return None, gallery, None, f"â— Chyba: {e}", history, 0

        async def run_exif_extraction(image_path: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku Å¾Ã¡dnÃ© EXIF, logika! ğŸ“·"
                return None, [], "", "â— Nahraj obrÃ¡zek!", history, 0
            progress_bar.value = 50
            try:
                result = forensic_tools.extract_exif(image_path)
                exif_text = "\n".join([f"{k}: {v}" for k, v in result.items()]) if result.get("error") is None else result["error"]
                history.append({"action": "extrahovat_exif", "output": None})
                status.value = "**Stav:** EXIF vytaÅ¾en, vÅ¡echno vÃ­me! ğŸ‰"
                return None, gallery, exif_text, "âœ… EXIF extrahovÃ¡na!", history, 100
            except Exception as e:
                status.value = "**Stav:** EXIF extrakce selhala, metadata se schovala! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", "â— EXIF selhal!", history, 0

        async def sdxl_text2img(prompt, negative_prompt, steps, guidance):
            if not prompt:
                status.value = "**Stav:** Bez popisu nic negeneruju, gÃ©nius! ğŸ“"
                return None, [], "â— Zadej popis!", action_history, 0
            progress_bar.value = 50
            try:
                result = sdxl_runner.generate_text2img(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    num_steps=int(steps),
                    guidance_scale=guidance
                )
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                result.save(output_path)
                action_history.append({"action": "sdxl_text2img", "output": output_path})
                output_gallery.append(output_path)
                status.value = "**Stav:** SDXL vygeneroval umÄ›leckÃ½ kousek! ğŸ‰"
                return result, output_gallery, "âœ… ObrÃ¡zek hotov!", action_history, 100
            except Exception as e:
                status.value = "**Stav:** SDXL se zasekl, asi Å¡patnÃ½ prompt! ğŸ˜µ"
                return None, output_gallery, f"â— Chyba: {e}", action_history, 0

        async def sdxl_img2img(image_path: str, prompt, strength, negative_prompt, steps, guidance):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku Å¾Ã¡dnÃ½ img2img, logika! ğŸ“·"
                return None, [], "â— Nahraj obrÃ¡zek!", action_history, 0
            progress_bar.value = 50
            try:
                with Image.open(image_path) as img:
                    result = sdxl_runner.generate_img2img(
                        input_image=img,
                        prompt=prompt,
                        strength=strength,
                        negative_prompt=negative_prompt,
                        num_steps=int(steps),
                        guidance_scale=guidance
                    )
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                result.save(output_path)
                action_history.append({"action": "sdxl_img2img", "output": output_path})
                output_gallery.append(output_path)
                status.value = "**Stav:** SDXL img2img hotov, jsi umÄ›lec! ğŸ‰"
                return result, output_gallery, "âœ… ObrÃ¡zek hotov!", action_history, 100
            except Exception as e:
                status.value = "**Stav:** SDXL img2img selhal, asi Å¡patnÃ½ den! ğŸ˜µ"
                return None, output_gallery, f"â— Chyba: {e}", action_history, 0

        def sdxl_save(image, prompt):
            if image is None:
                status.value = "**Stav:** Å½Ã¡dnÃ½ obrÃ¡zek, co chceÅ¡ uklÃ¡dat? ğŸ“·"
                return "â— Nic k uloÅ¾enÃ­!"
            return save_to_history(image, "sdxl", prompt)

        async def flux_text2img(prompt, negative_prompt, steps, guidance, sampler, lora_weight, width, height):
            if not prompt:
                status.value = "**Stav:** Bez popisu nic negeneruju, logika! ğŸ“"
                return None, [], "â— Zadej popis!", action_history, 0
            progress_bar.value = 50
            try:
                result = flux_runner.generate_text2img(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    num_steps=int(steps),
                    guidance_scale=guidance,
                    width=int(width),
                    height=int(height),
                    sampler=sampler,
                    lora_weight=lora_weight
                )
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                result.save(output_path)
                action_history.append({"action": "flux_text2img", "output": output_path})
                output_gallery.append(output_path)
                status.value = "**Stav:** Flux vygeneroval masterpiece! ğŸ‰"
                return result, output_gallery, "âœ… ObrÃ¡zek hotov!", action_history, 100
            except Exception as e:
                status.value = "**Stav:** Flux se zasekl, asi Å¡patnÃ½ prompt! ğŸ˜µ"
                return None, output_gallery, f"â— Chyba: {e}", action_history, 0

        async def flux_img2img(image_path: str, prompt, strength, negative_prompt, steps, guidance, sampler, lora_weight, width, height):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obrÃ¡zku Å¾Ã¡dnÃ½ img2img, gÃ©nius! ğŸ“·"
                return None, [], "â— Nahraj obrÃ¡zek!", action_history, 0
            progress_bar.value = 50
            try:
                with Image.open(image_path) as img:
                    result = flux_runner.generate_img2img(
                        input_image=img,
                        prompt=prompt,
                        strength=strength,
                        negative_prompt=negative_prompt,
                        num_steps=int(steps),
                        guidance_scale=guidance,
                        width=int(width),
                        height=int(height),
                        sampler=sampler,
                        lora_weight=lora_weight
                    )
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                result.save(output_path)
                action_history.append({"action": "flux_img2img", "output": output_path})
                output_gallery.append(output_path)
                status.value = "**Stav:** Flux img2img hotov, jsi Picasso! ğŸ‰"
                return result, output_gallery, "âœ… ObrÃ¡zek hotov!", action_history, 100
            except Exception as e:
                status.value = "**Stav:** Flux img2img selhal, asi Å¡patnÃ½ den! ğŸ˜µ"
                return None, output_gallery, f"â— Chyba: {e}", action_history, 0

        def flux_save(image, prompt):
            if image is None:
                status.value = "**Stav:** Å½Ã¡dnÃ½ obrÃ¡zek, co chceÅ¡ uklÃ¡dat? ğŸ“·"
                return "â— Nic k uloÅ¾enÃ­!"
            return save_to_history(image, "flux", prompt)

        async def run_export(preview_output: str, format: str, fps: int, export_name: str, 
                            history: List[Dict], gallery: List[str]):
            if not preview_output:
                status.value = "**Stav:** Nic k exportu, to je prÃ¡zdno! ğŸ“·"
                return None, [], "â— Nic k exportu!", history, 0
            progress_bar.value = 50
            try:
                output_name = export_name or get_next_output_filename(format.lower())
                if format == "MP4":
                    output_path = video_exporter.export_to_mp4(preview_output, output_name=output_name, fps=fps)
                elif format == "GIF":
                    output_path = video_exporter.export_to_gif(preview_output, output_name=output_name, fps=fps)
                else:
                    output_path = video_exporter.export_to_png_sequence(preview_output, output_dir_name=output_name)
                if output_path and Path(output_path).exists():
                    history.append({"action": "export", "output": output_path})
                    gallery.append(output_path)
                    status.value = "**Stav:** Export hotov, jsi Å¡Ã©f! ğŸ‰"
                    return None, gallery, f"âœ… Export dokonÄen: {output_path}", history, 100
                status.value = "**Stav:** Export selhal, nÄ›co smrdÃ­! ğŸ˜µ"
                return None, gallery, "â— Export selhal!", history, 100
            except Exception as e:
                status.value = "**Stav:** Export se zasekl! ğŸ˜µ"
                return None, gallery, f"â— Chyba: {e}", history, 0

        def show_history(history: List[Dict], filter_type: str) -> str:
            if not history:
                status.value = "**Stav:** Historie je prÃ¡zdnÃ¡, nic jsi nedÄ›lal! ğŸ“œ"
                return "â— Å½Ã¡dnÃ© akce!"
            filtered_history = history if filter_type == "VÅ¡e" else [h for h in history if filter_type.lower() in h["action"].lower()]
            return "\n".join([f"{i+1}. {action['action']}: {action['output'] or 'Å½Ã¡dnÃ½ vÃ½stup'}" for i, action in enumerate(filtered_history)])

        def save_project(history: List[Dict]):
            try:
                project_path = config.OUTPUT_DIR / "projects" / "project.json"
                project_path.parent.mkdir(exist_ok=True)
                with open(project_path, "w", encoding="utf-8") as f:
                    json.dump(history, f, indent=2, ensure_ascii=False)
                history.append({"action": "uloÅ¾it_projekt", "output": str(project_path)})
                status.value = "**Stav:** Projekt uloÅ¾en, jsi zorganizovanÃ½! ğŸ‰"
                return None, [], f"âœ… Projekt uloÅ¾en: {project_path}", history, 100
            except Exception as e:
                status.value = "**Stav:** UklÃ¡dÃ¡nÃ­ projektu selhalo, chaos vlÃ¡dne! ğŸ˜µ"
                return None, [], f"â— Chyba: {e}", history, 0

        def load_project(history: List[Dict]):
            try:
                project_path = config.OUTPUT_DIR / "projects" / "project.json"
                if not project_path.exists():
                    status.value = "**Stav:** Projekt neexistuje, co to hledÃ¡Å¡? ğŸ“œ"
                    return None, [], "â— Projekt neexistuje!", history, 0
                with open(project_path, "r", encoding="utf-8") as f:
                    loaded_history = json.load(f)
                history.clear()
                history.extend(loaded_history)
                status.value = "**Stav:** Projekt naÄten, jdeme dÃ¡l! ğŸ‰"
                return None, [], f"âœ… Projekt naÄten: {project_path}", history, 100
            except Exception as e:
                status.value = "**Stav:** NaÄÃ­tÃ¡nÃ­ projektu selhalo, nÄ›co smrdÃ­! ğŸ˜µ"
                return None, [], f"â— Chyba: {e}", history, 0

        def undo_action(history: List[Dict], gallery: List[str]):
            if history:
                last_action = history.pop()
                if last_action["output"] in gallery:
                    gallery.remove(last_action["output"])
                status.value = "**Stav:** Akce vrÃ¡cena, Äas se vrÃ¡til! â†©ï¸"
                return None, gallery, f"âœ… VrÃ¡cena akce: {last_action['action']}", history, 100
            status.value = "**Stav:** Nic k vrÃ¡cenÃ­, historie je prÃ¡zdnÃ¡! ğŸ“œ"
            return None, [], "â— Nic k vrÃ¡cenÃ­!", history, 0

        def download_youtube(url: str, output_path: str):
            ydl_opts = {
                "outtmpl": output_path,
                "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
                "merge_output_format": "mp4",
                "quiet": True
            }
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])
            logger.info(f"âœ… YouTube video staÅ¾eno: {output_path}")

        # PÅ™iÅ™azenÃ­ akcÃ­
        tabs.select(fn=update_active_tab, inputs=None, outputs=active_tab)
        source_selector.change(
            fn=update_source_selector,
            inputs=source_selector,
            outputs=[youtube_url, batch_dir]
        )
        lipsync_mode.change(
            fn=update_phoneme_timeline,
            inputs=[lipsync_mode, input_files],
            outputs=phoneme_timeline
        )
        upload_button.click(
            fn=upload_and_preview,
            inputs=[input_files, source_selector, youtube_url, batch_dir, action_history, stem_selector, output_gallery],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar, input_files, transcription_output, metadata_display]
        )
        generate_caption_button.click(
            fn=generate_deepdanbooru_caption,
            inputs=[input_files],
            outputs=[status]
        )
        clear_button.click(
            fn=clear_inputs,
            inputs=[action_history, output_gallery],
            outputs=[input_files, youtube_url, batch_dir, preview_output, gallery_output, status, action_history, progress_bar, input_files, transcription_output, metadata_display]
        )
        detect_face_button.click(
            fn=detect_face,
            inputs=[input_files, action_history, output_gallery],
            outputs=[face_output, gallery_output, status, action_history, progress_bar]
        )
        face_swap_button.click(
            fn=run_face_swap,
            inputs=[input_files, face_swap_target, action_history, output_gallery],
            outputs=[face_output, gallery_output, status, action_history, progress_bar]
        )
        apply_expression_button.click(
            fn=apply_expression,
            inputs=[input_files, expression_slider, expression_model, action_history, output_gallery],
            outputs=[face_output, gallery_output, status, action_history, progress_bar]
        )
        toggle_camera.click(
            fn=toggle_camera_stream,
            inputs=[],
            outputs=[preview_output]
        )
        lipsync_button.click(
            fn=run_lipsync,
            inputs=[input_files, input_files, lipsync_mode, action_history, output_gallery],
            outputs=[lipsync_output, gallery_output, status, action_history, progress_bar]
        )
        upscale_button.click(
            fn=run_upscale,
            inputs=[input_files, upscale_model, upscale_factor, batch_upscale, input_files, action_history, output_gallery],
            outputs=[upscale_output, gallery_output, status, action_history, progress_bar]
        )
        segment_button.click(
            fn=run_segmentation,
            inputs=[input_files, segment_mode, segment_prompt, action_history, output_gallery],
            outputs=[segment_output, gallery_output, status, action_history, progress_bar]
        )
        separate_stems_button.click(
            fn=separate_stems,
            inputs=[input_files, stem_selector, action_history, output_gallery],
            outputs=[audio_output, gallery_output, status, action_history, progress_bar]
        )
        transcribe_button.click(
            fn=transcribe_audio,
            inputs=[input_files, action_history, output_gallery],
            outputs=[audio_output, gallery_output, transcription_output, status, action_history, progress_bar]
        )
        apply_effect_button.click(
            fn=apply_audio_effect,
            inputs=[input_files, audio_effect, action_history, output_gallery],
            outputs=[audio_output, gallery_output, status, action_history, progress_bar]
        )
        forensic_button.click(
            fn=run_artifact_analysis,
            inputs=[input_files, compare_image, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, status, action_history, progress_bar]
        )
        ela_button.click(
            fn=run_ela_analysis,
            inputs=[input_files, compare_image, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, status, action_history, progress_bar]
        )
        deepfake_button.click(
            fn=run_deepfake_detection,
            inputs=[input_files, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, deepfake_plot, status, action_history, progress_bar]
        )
        exif_button.click(
            fn=run_exif_extraction,
            inputs=[input_files, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, exif_output, status, action_history, progress_bar]
        )
        report_button.click(
            fn=lambda x, h, g: (None, g, "ğŸ“œ PDF zprÃ¡va generovÃ¡na!", h, 100),  # Placeholder pro PDF generovÃ¡nÃ­
            inputs=[input_files, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, status, action_history, progress_bar]
        )
        sdxl_text2img_button.click(
            fn=sdxl_text2img,
            inputs=[sdxl_prompt, sdxl_negative_prompt, sdxl_steps, sdxl_guidance],
            outputs=[sdxl_output, gallery_output, status, action_history, progress_bar]
        )
        sdxl_img2img_button.click(
            fn=sdxl_img2img,
            inputs=[input_files, sdxl_prompt, sdxl_strength, sdxl_negative_prompt, sdxl_steps, sdxl_guidance],
            outputs=[sdxl_output, gallery_output, status, action_history, progress_bar]
        )
        sdxl_save_button.click(
            fn=sdxl_save,
            inputs=[sdxl_output, sdxl_prompt],
            outputs=[status]
        )
        flux_text2img_button.click(
            fn=flux_text2img,
            inputs=[flux_prompt, flux_negative_prompt, flux_steps, flux_guidance, flux_sampler, flux_lora_weight, flux_width, flux_height],
            outputs=[flux_output, gallery_output, status, action_history, progress_bar]
        )
        flux_img2img_button.click(
            fn=flux_img2img,
            inputs=[input_files, flux_prompt, flux_strength, flux_negative_prompt, flux_steps, flux_guidance, flux_sampler, flux_lora_weight, flux_width, flux_height],
            outputs=[flux_output, gallery_output, status, action_history, progress_bar]
        )
        flux_save_button.click(
            fn=flux_save,
            inputs=[flux_output, flux_prompt],
            outputs=[status]
        )
        export_button.click(
            fn=run_export,
            inputs=[preview_output, export_format, export_fps, export_name, action_history, output_gallery],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar]
        )
        save_project_button.click(
            fn=save_project,
            inputs=[action_history],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar]
        )
        load_project_button.click(
            fn=load_project,
            inputs=[action_history],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar]
        )
        undo_button.click(
            fn=undo_action,
            inputs=[action_history, output_gallery],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar]
        )
        show_history_button.click(
            fn=show_history,
            inputs=[action_history, history_filter],
            outputs=[history_display]
        )
        refresh_history_button.click(
            fn=lambda: get_history_images(),
            inputs=[],
            outputs=[history_gallery]
        )
        export_history_csv.click(
            fn=export_history_to_csv,
            inputs=[action_history],
            outputs=[status]
        )
        # NOVÃ‰: RychlÃ© akce
        quick_detect.click(
            fn=detect_face,
            inputs=[input_files, action_history, output_gallery],
            outputs=[face_output, gallery_output, status, action_history, progress_bar]
        )
        quick_upscale.click(
            fn=run_upscale,
            inputs=[input_files, upscale_model, upscale_factor, batch_upscale, input_files, action_history, output_gallery],
            outputs=[upscale_output, gallery_output, status, action_history, progress_bar]
        )
        quick_segment.click(
            fn=run_segmentation,
            inputs=[input_files, segment_mode, segment_prompt, action_history, output_gallery],
            outputs=[segment_output, gallery_output, status, action_history, progress_bar]
        )

    logger.info("ğŸ‰ GUI je ready! OtevÅ™i http://0.0.0.0:7860 a rozpoutej pixelovÃ© peklo! ğŸ”¥")
    return app

if __name__ == "__main__":
    try:
        app = create_gui()
        app.launch(
            inbrowser=True,
            server_name="0.0.0.0",
            server_port=7860,
            max_threads=10,
            queue_max_size=100,
            show_error=True
        )
        logger.info("ğŸš€ GUI bÄ›Å¾Ã­! Jdi na http://0.0.0.0:7860 a tvoÅ™, nebo zemÅ™i! ğŸ”¥")
    except Exception as e:
        logger.error(f"ğŸ’¥ GUI se zhroutilo: {e}. To je masakr, kÃ¡mo! ğŸ˜µ")
        input("Stiskni klÃ¡vesu a zkus to znova... Pixely ÄekajÃ­! ğŸ˜ˆ")