# gui/layout.py
"""
wAllICzech AI Studio 2025 ‚Äì GUI tak ≈°√≠lenƒõ cool, ≈æe Matrix pad√° z√°vist√≠! üé®
Kompletn√≠ verze s oran≈æovo-ƒçern√Ωm designem, pokroƒçil√Ωmi funkcemi a ≈†vejk≈Øv humor! üòà
"""
import gradio as gr
import logging
import cv2
import json
from pathlib import Path
from pytube import YouTube
import yt_dlp
from moviepy.editor import VideoFileClip
import numpy as np
import asyncio
from typing import List, Dict, Optional
from PIL import Image
import time
import os
import exifread
import mutagen
import torch
from core.image_processor import ImageProcessor
from core.flux_runner import FluxRunner
from core.sdxl_runner import SDXLRunner
from core.lipsync_engine import LipsyncEngine
from core.forensic_tools import ForensicTools
from core.segmenter import Segmenter
from core.video_exporter import VideoExporter
from core.audio_processor import AudioProcessor
from core.face_swapper import FaceSwapper
from core.upscaler import Upscaler
from core.expression_editor import ExpressionEditor
from utils.helpers import Config
from main import get_next_output_filename
import plotly.express as px  # NOV√â: Pro vizualizaci phoneme timeline a deepfake sk√≥re
import pandas as pd  # NOV√â: Pro export historie do CSV

logger = logging.getLogger(__name__)
logger.info("üöÄ GUI se rozj√≠≈æd√≠... P≈ôipni si p√°sy, bude to pixelov√Ω masakr! üî•")

def get_file_metadata(file_path: str) -> str:
    """Vyt√°hne metadata, nebo tƒõ po≈°le do pixelov√Ωho pekla! üòà"""
    if not file_path or not Path(file_path).exists():
        return "‚ùó ≈Ω√°dn√Ω soubor, ≈æ√°dn√° z√°bava! Nahraj nƒõco, lenochu! üò§"
    
    metadata = []
    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
    metadata.append(f"üìè Velikost: {file_size:.2f} MB")
    
    try:
        if file_path.endswith((".jpg", ".jpeg", ".png")):
            with Image.open(file_path) as img:
                width, height = img.size
                metadata.append(f"üìê Rozli≈°en√≠: {width}√ó{height}")
                metadata.append(f"üñºÔ∏è Form√°t: {img.format}")
                if img.format == "JPEG":
                    quality = img.info.get('quality', 'Nen√≠ zn√°ma')
                    metadata.append(f"üîç Kvalita: Odhad {quality}")
            with open(file_path, "rb") as f:
                tags = exifread.process_file(f)
                if tags:
                    metadata.append("üìã EXIF:")
                    for key, value in tags.items():
                        metadata.append(f"  {key}: {value}")
        
        elif file_path.endswith((".mp4", ".avi")):
            video = VideoFileClip(file_path)
            width, height = video.size
            duration = video.duration
            bitrate = os.path.getsize(file_path) * 8 / duration / 1000  # kbps
            metadata.append(f"üìê Rozli≈°en√≠: {width}√ó{height}")
            metadata.append(f"‚è±Ô∏è D√©lka: {duration:.2f} s")
            metadata.append(f"üìπ Bitrate: {bitrate:.2f} kbps")
            metadata.append(f"üéûÔ∏è Form√°t: {Path(file_path).suffix}")
            video.close()
        
        elif file_path.endswith((".mp3", ".wav")):
            audio = mutagen.File(file_path)
            duration = audio.info.length if audio.info else 0
            bitrate = audio.info.bitrate / 1000 if hasattr(audio.info, "bitrate") else 0
            metadata.append(f"‚è±Ô∏è D√©lka: {duration:.2f} s")
            metadata.append(f"üéµ Bitrate: {bitrate:.2f} kbps")
            metadata.append(f"üîä Form√°t: {Path(file_path).suffix}")
        
        return "\n".join(metadata) or "‚ùì Tenhle soubor je tajn≈Østk√°≈ô! Nic o nƒõm nev√≠me! üòí"
    except Exception as e:
        return f"‚ùó Metadata selhala: {e}. Ten soubor je asi z jin√© dimenze! üåå"

def generate_deepdanbooru_caption(image_path: str) -> str:
    """DeepDanbooru ti pop√≠≈°e obr√°zek, i kdy≈æ je slepej jako patron! üòÇ"""
    try:
        from deepdanbooru import DeepDanbooru
        model = DeepDanbooru()
        with Image.open(image_path) as img:
            tags = model.generate_tags(img)
        return f"üìú DeepDanbooru ≈ô√≠k√°: {', '.join(tags)}"
    except Exception as e:
        return f"‚ùó DeepDanbooru se zasekl: {e}. Asi m√° kocovinu! üòµ"

def create_gui():
    """Vytvo≈ô√≠ GUI, co tƒõ rozsek√° jako pixely v blenderu! üòà"""
    Config.ensure_dirs()
    
    # Inicializace model≈Ø ‚Äì a≈• se nikdo nefl√°k√°!
    model_status = {
        "ImageProcessor": False,
        "FluxRunner": False,
        "SDXLRunner": False,
        "LipsyncEngine": False,
        "ForensicTools": False,
        "Segmenter": False,
        "VideoExporter": True,
        "AudioProcessor": False,
        "FaceSwapper": False,
        "Upscaler": False,
        "ExpressionEditor": False
    }

    # NOV√â: Asynchronn√≠ naƒç√≠t√°n√≠ model≈Ø
    async def load_models_async():
        tasks = []
        try:
            processor = ImageProcessor()
            model_status["ImageProcessor"] = True
            logger.info("‚úÖ ImageProcessor je ready, pixely se t≈ôesou strachy!")
        except Exception as e:
            logger.error(f"‚ùå ImageProcessor se rozsypal: {e}. Pixely v pl√°ƒçi!")
        
        try:
            flux_runner = FluxRunner()
            model_status["FluxRunner"] = True
            logger.info("‚úÖ FluxRunner je ready, umƒõn√≠ se rod√≠!")
        except Exception as e:
            logger.error(f"‚ùå FluxRunner selhal: {e}. Umƒõn√≠ je mrtv√©!")
        
        try:
            sdxl_runner = SDXLRunner()
            model_status["SDXLRunner"] = True
            logger.info("‚úÖ SDXLRunner je ready, generuje jako ≈°√≠len√Ω!")
        except Exception as e:
            logger.error(f"‚ùå SDXLRunner selhal: {e}. Kreativita v prachu!")
        
        try:
            lipsync_engine = LipsyncEngine()
            model_status["LipsyncEngine"] = True
            logger.info("‚úÖ LipsyncEngine je ready, rty se synchronizuj√≠!")
        except Exception as e:
            logger.error(f"‚ùå LipsyncEngine selhal: {e}. Rty ztuhly!")
        
        try:
            forensic_tools = ForensicTools(model_name="retinaface")
            model_status["ForensicTools"] = True
            logger.info("‚úÖ ForensicTools jsou ready, pravda se odhal√≠!")
        except Exception as e:
            logger.error(f"‚ùå ForensicTools selhaly: {e}. Pravda z≈Østane skryt√°!")
        
        try:
            segmenter = Segmenter(use_grounding_dino=False)
            model_status["Segmenter"] = True
            logger.info("‚úÖ Segmenter je ready, pozad√≠ jde pod n≈Ø≈æ!")
        except Exception as e:
            logger.error(f"‚ùå Segmenter selhal: {e}. Pozad√≠ z≈Østane!")
        
        try:
            audio_processor = AudioProcessor()
            model_status["AudioProcessor"] = True
            logger.info("‚úÖ AudioProcessor je ready, zvuk se t≈ô√≠d√≠!")
        except Exception as e:
            logger.error(f"‚ùå AudioProcessor selhal: {e}. Ticho p≈ôed bou≈ô√≠!")
        
        try:
            face_swapper = FaceSwapper()
            model_status["FaceSwapper"] = True
            logger.info("‚úÖ FaceSwapper je ready, obliƒçeje se mƒõn√≠!")
        except Exception as e:
            logger.error(f"‚ùå FaceSwapper selhal: {e}. Obliƒçej z≈Østane tv≈Øj!")
        
        try:
            upscaler = Upscaler()
            model_status["Upscaler"] = True
            logger.info("‚úÖ Upscaler je ready, pixely se zvƒõt≈°uj√≠!")
        except Exception as e:
            logger.error(f"‚ùå Upscaler selhal: {e}. Pixely z≈Østanou mal√Ω!")
        
        try:
            expression_editor = ExpressionEditor()
            model_status["ExpressionEditor"] = True
            logger.info("‚úÖ ExpressionEditor je ready, v√Ωrazy se mƒõn√≠!")
        except Exception as e:
            logger.error(f"‚ùå ExpressionEditor selhal: {e}. V√Ωraz z≈Østane kamenn√Ω!")
            logger.warning("‚ö†Ô∏è FOMM modely chyb√≠? Mediapipe aspo≈à nezasp√≠!")
        
        return processor, flux_runner, sdxl_runner, lipsync_engine, forensic_tools, segmenter, audio_processor, face_swapper, upscaler, expression_editor

    # Spust√≠ asynchronn√≠ naƒç√≠t√°n√≠ model≈Ø
    processor, flux_runner, sdxl_runner, lipsync_engine, forensic_tools, segmenter, audio_processor, face_swapper, upscaler, expression_editor = asyncio.run(load_models_async())
    
    video_exporter = VideoExporter()
    logger.info("‚úÖ VideoExporter je ready, exportuje jako ≈°√©f!")

    # Dynamick√Ω dropdown pro expression modely
    expression_models = ["Mediapipe"]
    if ExpressionEditor.is_fomm_available():
        expression_models.append("FOMM")
    logger.info(f"üé≠ Dostupn√© modely pro v√Ωrazy: {expression_models}")

    # Historie a v√Ωstupn√≠ slo≈æka
    config = Config()
    history_dir = config.OUTPUT_DIR / "history"
    history_dir.mkdir(parents=True, exist_ok=True)

    # NOV√â: Vylep≈°en√© CSS s animacemi a responzivn√≠m designem
    css = """
    .gradio-container { 
        background: linear-gradient(135deg, #ff6200, #000000);
        font-family: 'Arial', sans-serif; 
        color: #ffffff; 
    }
    h1 { 
        color: #ff6200; 
        text-align: center; 
        font-size: 2.5em; 
        text-shadow: 2px 2px 4px #000000; 
    }
    .tab-nav button { 
        background-color: #ff6200; 
        color: #000000; 
        border-radius: 8px; 
        padding: 12px; 
        font-weight: bold; 
        transition: background-color 0.3s ease, transform 0.2s; 
    }
    .tab-nav button:hover { 
        background-color: #e55b00; 
        transform: scale(1.05); 
    }
    .status-box { 
        background-color: rgba(0, 0, 0, 0.7); 
        padding: 15px; 
        border-radius: 8px; 
        margin: 10px 0; 
        color: #ff6200; 
        font-weight: bold; 
    }
    .history-gallery img { 
        border: 3px solid #ff6200; 
        border-radius: 8px; 
        transition: transform 0.2s; 
    }
    .history-gallery img:hover { 
        transform: scale(1.1); 
    }
    .gr-button-primary { 
        background-color: #ff6200 !important; 
        color: #000000 !important; 
        border: none !important; 
        transition: background-color 0.3s ease; 
    }
    .gr-button-primary:hover { 
        background-color: #e55b00 !important; 
    }
    .gr-button-secondary { 
        background-color: #333333 !important; 
        color: #ff6200 !important; 
        border: none !important; 
    }
    .gr-accordion { 
        background-color: rgba(255, 98, 0, 0.1); 
        border-radius: 8px; 
    }
    .progress-bar { 
        background: linear-gradient(90deg, #ff6200, #e55b00); 
        animation: pulse 2s infinite; 
    }
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.7; }
        100% { opacity: 1; }
    }
    @media (max-width: 768px) {
        .gradio-container { font-size: 0.9em; }
        .tab-nav button { padding: 8px; }
        .history-gallery img { width: 100%; }
    }
    .tooltip { 
        position: relative; 
    }
    .tooltip:hover:after { 
        content: attr(data-tooltip); 
        position: absolute; 
        bottom: 100%; 
        left: 50%; 
        transform: translateX(-50%); 
        background: #333; 
        color: #ff6200; 
        padding: 5px; 
        border-radius: 4px; 
        font-size: 0.8em; 
        white-space: nowrap; 
        z-index: 10; 
    }
    """

    with gr.Blocks(title="wAllICzech AI Studio 2025", css=css, theme=gr.themes.Soft()) as app:
        action_history = gr.State([])
        active_tab = gr.State("Obliƒçej üòä")
        output_gallery = gr.State([])

        # NOV√â: N√°hodn√° hl√°≈°ka p≈ôi naƒç√≠t√°n√≠
        random_quotes = [
            "P≈ôipravuji pixelov√© peklo, chvilku strpƒõn√≠! üî•",
            "≈†vejk by ≈ôekl: 'Tohle bude po≈ô√°dnej bordel!' üòà",
            "Naƒç√≠t√°m modely, pixely u≈æ se t≈ôesou! üé®",
            "Pixely se ≈ôad√≠ do z√°stupu, ƒçekej chvilku! üí™"
        ]
        gr.Markdown(
            f"# wAllICzech AI Studio 2025 üñºÔ∏èüé®\n"
            f"{random_quotes[np.random.randint(0, len(random_quotes))]}\n"
            "Jedno vstupn√≠ pole, v≈°echny funkce, metadata na oƒç√≠ch. "
            "P≈ôiprav se na AI, co tƒõ rozsek√° jako pixely v blenderu! üòà"
        )

        # Stavov√Ω box
        status = gr.Markdown("**Stav:** P≈ôipraven k pixelov√© apokalypse! üöÄ", elem_classes=["status-box"])
        # NOV√â: Animovan√Ω progres bar
        progress_bar = gr.Slider(minimum=0, maximum=100, value=0, label="Pr≈Øbƒõh (%)", interactive=False)

        with gr.Row():
            with gr.Column(scale=1, min_width=300):
                # Vstupn√≠ panel
                with gr.Accordion("Vstupn√≠ panel üìÇ", open=True):
                    gr.Markdown("**Nahraj soubor, nebo ≈†vejk bude na≈°tvan√Ω! üòà**")
                    # NOV√â: Jednotn√© vstupn√≠ pole
                    input_files = gr.File(
                        label="Nahr√°t soubory (obr√°zky, videa, audio)",
                        file_count="multiple",
                        file_types=["image", "video", "audio"],
                        elem_classes=["tooltip"],
                        elem_id="input-files",
                        data_tooltip="Nahraj, nebo tƒõ po≈°lu do pixelov√Ωho pekla! üòà"
                    )
                    source_selector = gr.Radio(
                        choices=["Soubory", "YouTube", "Kamera", "Adres√°≈ô"],
                        value="Soubory",
                        label="Zdroj",
                        info="Vyber, odkud chce≈° bordel."
                    )
                    youtube_url = gr.Textbox(
                        label="YouTube URL",
                        visible=False,
                        info="Vlo≈æ odkaz, nebo se ztra≈•!",
                        elem_classes=["tooltip"],
                        data_tooltip="Spr√°vn√Ω odkaz, nebo ≈†vejk ti d√° po ƒçuni! üò§"
                    )
                    # NOV√â: Batch processing z adres√°≈ôe
                    batch_dir = gr.Textbox(
                        label="Cesta k adres√°≈ôi",
                        visible=False,
                        info="Zadej cestu k adres√°≈ôi pro hromadn√© zpracov√°n√≠."
                    )
                    metadata_display = gr.Textbox(
                        label="Metadata souboru",
                        interactive=False,
                        lines=5,
                        value="üìã Nahraj nƒõco, nebo ti nic ne≈ôeknu! üò§"
                    )
                    generate_caption_button = gr.Button("Generovat popis üìú", variant="primary")
                    upload_button = gr.Button("Nahr√°t a zpracovat üì§", variant="primary")
                    clear_button = gr.Button("Vyƒçistit vstupy üóëÔ∏è", variant="secondary")

                # Rychl√© akce
                with gr.Accordion("Rychl√© akce ‚ö°", open=True):
                    quick_detect = gr.Button("Detekuj obliƒçeje üîç", variant="primary")
                    quick_upscale = gr.Button("Rychl√© zvƒõt≈°en√≠ üìà", variant="primary")
                    quick_segment = gr.Button("Rychl√° segmentace ‚úÇÔ∏è", variant="primary")

                # Stav model≈Ø
                with gr.Accordion("Stav model≈Ø üõ†Ô∏è", open=False):
                    status_textbox = gr.Textbox(
                        value="\n".join([f"{k}: {'‚úÖ Naƒçten' if v else '‚ùå Selhal'}" for k, v in model_status.items()]),
                        label="Stav inicializace model≈Ø",
                        interactive=False,
                        lines=10
                    )

            with gr.Column(scale=3, min_width=800):
                # N√°stroje
                gr.Markdown("## N√°stroje üõ†Ô∏è")
                with gr.Tabs() as tabs:
                    with gr.Tab(label="Obliƒçej üòä", id="face"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Detekce, v√Ωmƒõna obliƒçej≈Ø, √∫prava v√Ωraz≈Ø**")
                                face_swap_target = gr.File(
                                    label="C√≠lov√Ω obliƒçej pro v√Ωmƒõnu",
                                    file_types=["image"],
                                    elem_classes=["tooltip"],
                                    data_tooltip="Nahraj obliƒçej, nebo z≈Østane≈° s√°m sebou! üòè"
                                )
                                expression_slider = gr.Slider(
                                    minimum=-1.0, maximum=1.0, value=0.0,
                                    label="√ösmƒõv üòÑ",
                                    info="Uprav v√Ωraz (-1 = poh≈ôeb, 1 = karneval)."
                                )
                                expression_model = gr.Dropdown(
                                    choices=expression_models,
                                    value="Mediapipe",
                                    label="Model v√Ωraz≈Ø",
                                    info="Vyber, kdo ti zmƒõn√≠ ksicht."
                                )
                                with gr.Row():
                                    detect_face_button = gr.Button("Detekuj obliƒçeje üîç", variant="primary")
                                    face_swap_button = gr.Button("Vymƒõnit obliƒçej üîÑ", variant="primary")
                                    apply_expression_button = gr.Button("Aplikovat v√Ωraz ‚ú®", variant="primary")
                                toggle_camera = gr.Button("Zapnout/vypnout kameru üì∑", variant="secondary")
                            with gr.Column(scale=1):
                                face_output = gr.Image(label="V√Ωsledek", type="filepath")

                    with gr.Tab(label="Lipsync üé§", id="lipsync"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Synchronizace rt≈Ø, a≈• mluv√≠≈° jako prof√≠k!**")
                                lipsync_mode = gr.Dropdown(
                                    choices=["Automatick√Ω", "Manu√°ln√≠ korekce", "Hybridn√≠"],
                                    value="Automatick√Ω",
                                    label="Re≈æim lipsyncu",
                                    info="Vyber, jak moc chce≈° ≈ô√≠dit chaos."
                                )
                                # NOV√â: Interaktivn√≠ phoneme timeline
                                phoneme_timeline = gr.Plot(
                                    label="ƒåasov√° osa fon√©m≈Ø ‚è≥",
                                    visible=False,
                                    info="Uprav fon√©my p≈ôeta≈æen√≠m bod≈Ø."
                                )
                                lipsync_button = gr.Button("Spustit lipsync üé¨", variant="primary")
                            with gr.Column(scale=1):
                                lipsync_output = gr.Video(label="V√Ωsledek")

                    with gr.Tab(label="Zvƒõt≈°en√≠ üîé", id="upscale"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Zvƒõt≈°√≠me tv√© pixely, a≈• z√°vid√≠ Hubble!**")
                                upscale_model = gr.Dropdown(
                                    choices=["RealESRGAN_x4plus", "4x-UltraSharp"],
                                    value="RealESRGAN_x4plus",
                                    label="Model zvƒõt≈°en√≠",
                                    info="Vyber, co ti zvƒõt≈°√≠ ego."
                                )
                                upscale_factor = gr.Slider(
                                    minimum=1, maximum=4, value=2, step=1,
                                    label="Faktor zvƒõt≈°en√≠",
                                    info="2 = 2x vƒõt≈°√≠, logika!"
                                )
                                # NOV√â: Batch processing
                                batch_upscale = gr.Checkbox(
                                    label="Zpracovat v≈°echny soubory",
                                    value=False,
                                    info="Za≈°krtnƒõte pro hromadn√© zvƒõt≈°en√≠."
                                )
                                upscale_button = gr.Button("Zvƒõt≈°it obr√°zek üìà", variant="primary")
                            with gr.Column(scale=1):
                                upscale_output = gr.Image(label="V√Ωsledek", type="filepath")

                    with gr.Tab(label="Segmentace ‚úÇÔ∏è", id="segment"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Rozsekej pozad√≠ jako prof√≠k!**")
                                segment_mode = gr.Dropdown(
                                    choices=["Odstranit pozad√≠", "Rozmazat pozad√≠"],
                                    value="Odstranit pozad√≠",
                                    label="Re≈æim segmentace",
                                    info="Co s t√≠m pozad√≠m provedeme?"
                                )
                                segment_prompt = gr.Textbox(
                                    label="Textov√Ω popis",
                                    placeholder="nap≈ô. 'ƒçlovƒõk'",
                                    info="Co m√°me vy≈ô√≠znout?"
                                )
                                segment_button = gr.Button("Segmentovat ‚úÇÔ∏è", variant="primary")
                            with gr.Column(scale=1):
                                segment_output = gr.Image(label="V√Ωsledek", type="filepath")

                    with gr.Tab(label="Zvuk üéµ", id="audio"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Separuj a p≈ôepisuj zvuk jako ≈°√©f!**")
                                stem_selector = gr.CheckboxGroup(
                                    choices=["vok√°ly", "bic√≠", "basa", "ostatn√≠"],
                                    label="Vyber stopy pro separaci",
                                    value=["vok√°ly", "bic√≠", "basa", "ostatn√≠"],
                                    info="Co chce≈° oddƒõlit?"
                                )
                                # NOV√â: Live n√°hled zvukov√Ωch efekt≈Ø
                                audio_effect = gr.Dropdown(
                                    choices=["≈Ω√°dn√Ω", "Echo", "Reverb", "Pitch Shift"],
                                    value="≈Ω√°dn√Ω",
                                    label="P≈ôidat efekt",
                                    info="Vyber efekt pro live n√°hled."
                                )
                                with gr.Row():
                                    separate_stems_button = gr.Button("Separovat stopy üéôÔ∏è", variant="primary")
                                    transcribe_button = gr.Button("P≈ôepsat zvuk üìú", variant="primary")
                                    apply_effect_button = gr.Button("Aplikovat efekt üéµ", variant="primary")
                            with gr.Column(scale=1):
                                transcription_output = gr.Textbox(
                                    label="P≈ôepis zvuku",
                                    interactive=False,
                                    lines=5
                                )
                                audio_output = gr.Audio(label="N√°hled efektu")

                    with gr.Tab(label="Forenzn√≠ anal√Ωza üîç", id="forensic"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Odhal√≠me ka≈æd√Ω ≈°patn√Ω pixel!**")
                                # NOV√â: Porovn√°n√≠ dvou obr√°zk≈Ø
                                compare_image = gr.File(
                                    label="Druh√Ω obr√°zek pro porovn√°n√≠",
                                    file_types=["image"],
                                    elem_classes=["tooltip"],
                                    data_tooltip="Nahraj druh√Ω obr√°zek pro ELA/JPEG anal√Ωzu."
                                )
                                with gr.Row():
                                    forensic_button = gr.Button("Analyzovat JPEG artefakty üìä", variant="primary")
                                    ela_button = gr.Button("Error Level Analysis üîé", variant="primary")
                                    deepfake_button = gr.Button("Detekovat deepfake üïµÔ∏è‚Äç‚ôÇÔ∏è", variant="primary")
                                    exif_button = gr.Button("Extrahovat EXIF metadata üìã", variant="primary")
                                    report_button = gr.Button("Vygenerovat PDF zpr√°vu üìú", variant="primary")
                                # NOV√â: Deepfake sk√≥re graf
                                deepfake_plot = gr.Plot(label="Deepfake sk√≥re")
                            with gr.Column(scale=1):
                                exif_output = gr.Textbox(
                                    label="EXIF metadata",
                                    interactive=False,
                                    lines=5
                                )
                                forensic_output = gr.Image(label="V√Ωsledek anal√Ωzy", type="filepath")

                    with gr.Tab(label="Text na obr√°zek üé®", id="text2image"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Generuj umƒõn√≠, a≈• z√°vid√≠ Da Vinci!**")
                                sdxl_prompt = gr.Textbox(
                                    label="Prompt",
                                    value=config.config["models"]["diffusers"]["sdxl"]["default_prompt"],
                                    placeholder="Zadej popis, nap≈ô. 'Kyberpunkov√© mƒõsto'"
                                )
                                sdxl_negative_prompt = gr.Textbox(
                                    label="Negativn√≠ prompt",
                                    value=config.config["models"]["diffusers"]["sdxl"]["default_negative_prompt"],
                                    placeholder="Co nechce≈°, nap≈ô. 'rozmazan√©'"
                                )
                                sdxl_steps = gr.Slider(
                                    10, 100, value=config.config["models"]["diffusers"]["sdxl"]["default_steps"],
                                    label="Poƒçet krok≈Ø"
                                )
                                sdxl_guidance = gr.Slider(
                                    1.0, 15.0, value=config.config["models"]["diffusers"]["sdxl"]["default_guidance_scale"],
                                    label="Guidance Scale"
                                )
                                sdxl_strength = gr.Slider(
                                    0.1, 1.0, value=config.config["models"]["diffusers"]["sdxl"]["default_strength"],
                                    label="S√≠la (img2img)"
                                )
                                with gr.Row():
                                    sdxl_text2img_button = gr.Button("Generovat ‚ú®", variant="primary")
                                    sdxl_img2img_button = gr.Button("Stylizovat vstup üé®", variant="secondary")
                            with gr.Column(scale=1):
                                sdxl_output = gr.Image(label="V√Ωsledek", type="pil")
                                sdxl_save_button = gr.Button("Ulo≈æit do historie üíæ", variant="secondary")

                    with gr.Tab(label="Flux stylizace üé®", id="flux"):
                        with gr.Row():
                            with gr.Column(scale=2):
                                gr.Markdown("**Flux.1-dev ‚Äì umƒõn√≠ na steroidech!**")
                                flux_prompt = gr.Textbox(
                                    label="Prompt",
                                    value=config.config["models"]["diffusers"]["flux"]["default_prompt"],
                                    placeholder="Zadej popis, nap≈ô. 'Kr√°sn√Ω les'"
                                )
                                flux_negative_prompt = gr.Textbox(
                                    label="Negativn√≠ prompt",
                                    value=config.config["models"]["diffusers"]["flux"]["default_negative_prompt"],
                                    placeholder="Co nechce≈°, nap≈ô. 'rozmazan√©'"
                                )
                                flux_steps = gr.Slider(
                                    10, 100, value=config.config["models"]["diffusers"]["flux"]["default_steps"],
                                    label="Poƒçet krok≈Ø"
                                )
                                flux_guidance = gr.Slider(
                                    1.0, 15.0, value=config.config["models"]["diffusers"]["flux"]["default_guidance_scale"],
                                    label="Guidance Scale"
                                )
                                flux_strength = gr.Slider(
                                    0.1, 1.0, value=config.config["models"]["diffusers"]["flux"]["default_strength"],
                                    label="S√≠la (img2img)"
                                )
                                flux_sampler = gr.Dropdown(
                                    choices=["Euler", "DDIM", "DPM++ 2M Karras", "Euler Ancestral"],
                                    value="Euler",
                                    label="Sampler"
                                )
                                flux_lora_weight = gr.Slider(
                                    minimum=0.0, maximum=1.0, value=0.8, step=0.05,
                                    label="V√°ha LoRA"
                                )
                                flux_width = gr.Slider(
                                    minimum=256, maximum=2048, value=512, step=8,
                                    label="≈†√≠≈ôka v√Ωstupu"
                                )
                                flux_height = gr.Slider(
                                    minimum=256, maximum=2048, value=512, step=8,
                                    label="V√Ω≈°ka v√Ωstupu"
                                )
                                with gr.Row():
                                    flux_text2img_button = gr.Button("Generovat ‚ú®", variant="primary")
                                    flux_img2img_button = gr.Button("Stylizovat vstup üé®", variant="secondary")
                            with gr.Column(scale=1):
                                flux_output = gr.Image(label="V√Ωsledek", type="pil")
                                flux_save_button = gr.Button("Ulo≈æit do historie üíæ", variant="secondary")

                # N√°hledov√Ω panel
                gr.Markdown("## N√°hledov√Ω panel üñ•Ô∏è")
                with gr.Tabs():
                    with gr.Tab("Jednotliv√Ω n√°hled"):
                        preview_output = gr.Image(label="V√Ωstupn√≠ n√°hled", interactive=False, height=600)
                    with gr.Tab("Galerie v√Ωstup≈Ø"):
                        gallery_output = gr.Gallery(label="V≈°echny v√Ωstupy", columns=3, height=600)

                # Export a spr√°va
                with gr.Accordion("Export a spr√°va üíæ", open=False):
                    export_format = gr.Dropdown(
                        choices=["MP4", "GIF", "PNG sekvence"],
                        value="MP4",
                        label="Form√°t exportu"
                    )
                    export_fps = gr.Slider(
                        minimum=1, maximum=60, value=30, step=1,
                        label="FPS"
                    )
                    export_name = gr.Textbox(
                        label="N√°zev v√Ωstupu",
                        placeholder="nap≈ô. output.mp4"
                    )
                    # NOV√â: Export historie do CSV
                    export_history_csv = gr.Button("Exportovat historii jako CSV üìä", variant="secondary")
                    with gr.Row():
                        export_button = gr.Button("Exportovat v√Ωsledek üì§", variant="primary")
                        save_project_button = gr.Button("Ulo≈æit projekt üíæ", variant="primary")
                        load_project_button = gr.Button("Naƒç√≠st projekt üìÇ", variant="primary")
                        undo_button = gr.Button("Vr√°tit akci ‚Ü©Ô∏è", variant="secondary")

                # Historie akc√≠
                with gr.Accordion("Historie akc√≠ üìú", open=False):
                    # NOV√â: Filtrov√°n√≠ historie
                    history_filter = gr.Dropdown(
                        choices=["V≈°e", "Lipsync", "Upscale", "Segmentace", "Zvuk", "Forenzn√≠", "SDXL", "Flux"],
                        value="V≈°e",
                        label="Filtrovat akce"
                    )
                    history_display = gr.Textbox(
                        label="Proveden√© akce",
                        interactive=False,
                        lines=5
                    )
                    show_history_button = gr.Button("Zobrazit historii ‚Ü©Ô∏è", variant="secondary")
                    history_gallery = gr.Gallery(
                        label="Vygenerovan√© obr√°zky",
                        value=[str(p) for p in history_dir.glob("*.png")],
                        columns=4,
                        height="auto",
                        preview=True
                    )
                    refresh_history_button = gr.Button("Obnovit historii üîÑ", variant="secondary")

        # Funkce pro aktualizaci GUI
        async def update_active_tab(tab_id: Optional[str] = None) -> str:
            tab_names = {
                "face": "Obliƒçej ÔøΩÂú∞‰∏ã",
                "lipsync": "Lipsync üé§",
                "upscale": "Zvƒõt≈°en√≠ üîé",
                "segment": "Segmentace ‚úÇÔ∏è",
                "audio": "Zvuk üéµ",
                "forensic": "Forenzn√≠ anal√Ωza üîç",
                "text2image": "Text na obr√°zek üé®",
                "flux": "Flux stylizace üé®"
            }
            return tab_names.get(tab_id, "Obliƒçej üòä")

        def update_source_selector(source: str):
            return (
                gr.update(visible=source == "YouTube"),
                gr.update(visible=source == "Adres√°≈ô")
            )

        # NOV√â: Phoneme timeline
        def update_phoneme_timeline(mode: str, audio_path: str):
            if mode not in ["Manu√°ln√≠ korekce", "Hybridn√≠"] or not audio_path:
                return gr.update(visible=False, value=None)
            try:
                # Simulace phoneme dat (v re√°lu bys pou≈æil audio_processor.analyze_phonemes)
                times = np.linspace(0, 5, 10)
                phonemes = ["aa", "ee", "oo", "sil", "aa", "ee", "oo", "sil", "aa", "ee"]
                df = pd.DataFrame({"Time (s)": times, "Phoneme": phonemes})
                fig = px.scatter(df, x="Time (s)", y="Phoneme", title="Phoneme Timeline")
                return gr.update(visible=True, value=fig)
            except Exception as e:
                logger.error(f"‚ùå Phoneme timeline selhal: {e}")
                return gr.update(visible=False, value=None)

        def save_to_history(image: Image.Image, model: str, prompt: str) -> str:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_path = history_dir / f"{model}_{timestamp}_{prompt[:20].replace(' ', '_')}.png"
            image.save(output_path)
            logger.info(f"üìú Obr√°zek ulo≈æen do historie: {output_path}")
            return str(output_path)

        def get_history_images():
            return [str(p) for p in history_dir.glob("*.png")]

        # NOV√â: Export historie do CSV
        def export_history_to_csv(history: List[Dict]):
            if not history:
                status.value = "**Stav:** Historie je pr√°zdn√°, nic jsi nedƒõlal! üìú"
                return "‚ùó Historie je pr√°zdn√°!"
            df = pd.DataFrame(history)
            output_path = config.OUTPUT_DIR / f"history_{time.strftime('%Y%m%d_%H%M%S')}.csv"
            df.to_csv(output_path, index=False)
            logger.info(f"üìä Historie exportov√°na: {output_path}")
            return f"‚úÖ Historie exportov√°na: {output_path}"

        async def upload_and_preview(files: List[str], source: str, youtube_url: str, batch_dir: str, 
                                   history: List[Dict], stem_selector: List[str], gallery: List[str]):
            progress_bar.value = 10
            file_path = None
            if source == "Soubory" and files:
                file_path = files[0]  # Prvn√≠ soubor pro n√°hled
            elif source == "YouTube" and youtube_url:
                try:
                    progress_bar.value = 30
                    output_path = config.OUTPUT_DIR / get_next_output_filename("mp4")
                    download_youtube(youtube_url, str(output_path))
                    history.append({"action": "youtube_st√°hnout", "output": str(output_path)})
                    gallery.append(str(output_path))
                    progress_bar.value = 50
                    audio_path = config.OUTPUT_DIR / get_next_output_filename("wav")
                    video = VideoFileClip(str(output_path))
                    video.audio.write_audiofile(str(audio_path))
                    video.close()
                    progress_bar.value = 70
                    stem_result = audio_processor.separate_audio_demucs(str(audio_path), stem_selector)
                    history.append({"action": "separovat_stopy", "output": stem_result["output_paths"]})
                    progress_bar.value = 90
                    transcribe_result = audio_processor.transcribe_audio(str(audio_path))
                    history.append({"action": "p≈ôepsat_zvuk", "output": transcribe_result["output_path"]})
                    status.value = "**Stav:** YouTube video sta≈æeno! üéâ"
                    return None, gallery, f"‚úÖ YouTube video sta≈æeno: {output_path}", history, 100, audio_path, transcribe_result["transcription"], get_file_metadata(str(output_path))
                except Exception as e:
                    status.value = "**Stav:** YouTube se zasekl! üòµ"
                    return None, [], f"‚ùó Chyba: {e}", history, 0, None, "", "‚ùó YouTube selhal!"
            elif source == "Kamera":
                try:
                    progress_bar.value = 50
                    cap = cv2.VideoCapture(0)
                    if not cap.isOpened():
                        status.value = "**Stav:** Kamera je mimo! üì∑"
                        raise ValueError("Kamera zaspala!")
                    ret, frame = cap.read()
                    cap.release()
                    if ret:
                        output_path = config.OUTPUT_DIR / get_next_output_filename("jpg")
                        cv2.imwrite(str(output_path), frame)
                        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        history.append({"action": "kamera_sn√≠mek", "output": str(output_path)})
                        gallery.append(str(output_path))
                        status.value = "**Stav:** Sn√≠mek ulo≈æen! üéâ"
                        return img, gallery, f"‚úÖ Sn√≠mek ulo≈æen: {output_path}", history, 100, None, "", get_file_metadata(str(output_path))
                    status.value = "**Stav:** Kamera selhala! üòµ"
                    return None, [], "‚ùó Kamera selhala!", history, 0, None, "", "‚ùó Kamera je mimo!"
                except Exception as e:
                    status.value = "**Stav:** Kamera je v h√°ji! üòµ"
                    return None, [], f"‚ùó Chyba: {e}", history, 0, None, "", "‚ùó Kamera zaspala!"
            elif source == "Adres√°≈ô" and batch_dir:
                try:
                    batch_path = Path(batch_dir)
                    if not batch_path.is_dir():
                        status.value = "**Stav:** Adres√°≈ô neexistuje! üìÇ"
                        return None, [], "‚ùó Adres√°≈ô neexistuje!", history, 0, None, "", "‚ùó ≈†patn√° cesta!"
                    files = [str(p) for p in batch_path.glob("*") if p.suffix in [".jpg", ".png", ".mp4", ".avi", ".mp3", ".wav"]]
                    if not files:
                        status.value = "**Stav:** Adres√°≈ô je pr√°zdn√Ω! üìÇ"
                        return None, [], "‚ùó ≈Ω√°dn√© soubory!", history, 0, None, "", "‚ùó Pr√°zdn√Ω adres√°≈ô!"
                    file_path = files[0]
                    history.append({"action": "nahr√°t_adres√°≈ô", "output": batch_dir})
                    gallery.extend(files)
                    status.value = "**Stav:** Adres√°≈ô nahr√°n! üéâ"
                    return None, gallery, f"‚úÖ Nahr√°n adres√°≈ô: {batch_dir}", history, 100, None, "", get_file_metadata(file_path)
                except Exception as e:
                    status.value = "**Stav:** Adres√°≈ô selhal! üòµ"
                    return None, [], f"‚ùó Chyba: {e}", history, 0, None, "", "‚ùó Adres√°≈ô je mimo!"
            
            if file_path and Path(file_path).exists():
                history.append({"action": f"nahr√°t_{source.lower()}", "output": file_path})
                gallery.append(file_path)
                status.value = f"**Stav:** {source} nahr√°n! üéâ"
                return None, gallery, f"‚úÖ {source} nahr√°n!", history, 100, None, "", get_file_metadata(file_path)
            status.value = "**Stav:** Nic jsi nenahr√°l, troll√≠≈° mƒõ? üò§"
            return None, [], "‚ùó Nahraj nƒõco!", history, 0, None, "", "‚ùó ≈Ω√°dn√Ω soubor!"

        def clear_inputs(history: List[Dict], gallery: List[str]):
            history.append({"action": "vyƒçistit_vstupy", "output": None})
            gallery.clear()
            status.value = "**Stav:** V≈°e vyƒçi≈°tƒõno, jako po v√Ωbuchu! üóëÔ∏è"
            return None, [], None, None, [], "‚úÖ V≈°e vyƒçi≈°tƒõno!", history, 100, None, "", "üìã ≈Ω√°dn√° metadata, nahraj nƒõco!"

        async def detect_face(image_path: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku to nep≈Øjde, g√©nius! üì∑"
                return None, [], "‚ùó Nahraj obr√°zek!", history, 0
            progress_bar.value = 50
            try:
                img = processor.load_image(image_path)
                faces = processor.detect_faces(img)
                if faces:
                    img_with_faces = processor.draw_faces(img, faces)
                    output_path = config.OUTPUT_DIR / get_next_output_filename("jpg")
                    cv2.imwrite(str(output_path), cv2.cvtColor(img_with_faces, cv2.COLOR_RGB2BGR))
                    history.append({"action": "detekovat_obliƒçej", "output": output_path})
                    gallery.append(output_path)
                    status.value = f"**Stav:** Nalezeno {len(faces)} obliƒçej≈Ø! üéâ"
                    return output_path, gallery, f"‚úÖ Nalezeno {len(faces)} obliƒçej≈Ø!", history, 100
                status.value = "**Stav:** ≈Ω√°dn√© obliƒçeje, co to je, duch? üëª"
                return img, gallery, "‚ùó ≈Ω√°dn√© obliƒçeje!", history, 100
            except Exception as e:
                status.value = "**Stav:** Detekce obliƒçej≈Ø se podƒõlala! üòµ"
                return None, [], f"‚ùó Chyba: {e}", history, 0

        async def run_face_swap(image_path: str, target_image: str, history: List[Dict], gallery: List[str]):
            if not image_path or not target_image or not Path(image_path).exists() or not Path(target_image).exists():
                status.value = "**Stav:** Chyb√≠ obr√°zky, to jako v√°≈ænƒõ? üì∑"
                return None, [], "‚ùó Nahraj oba obr√°zky!", history, 0
            progress_bar.value = 50
            try:
                result = face_swapper.swap_face(image_path, target_image)
                output_path = config.OUTPUT_DIR / get_next_output_filename("jpg")
                cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                history.append({"action": "vymƒõnit_obliƒçej", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** Obliƒçej vymƒõnƒõn, vypad√°≈° jako celebrita! üéâ"
                return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** V√Ωmƒõna obliƒçej≈Ø se zasekla! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", history, 0

        async def apply_expression(image_path: str, expression_value: float, expression_model: str, 
                                 history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku ≈æ√°dn√Ω v√Ωraz, logika! üì∑"
                return None, [], "‚ùó Nahraj obr√°zek!", history, 0
            progress_bar.value = 50
            try:
                result = expression_editor.apply_expression(image_path, expression_value, expression_model, line_color=(0, 255, 0))
                output_path = config.OUTPUT_DIR / get_next_output_filename("jpg")
                cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                history.append({"action": "aplikovat_v√Ωraz", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** V√Ωraz aplikov√°n, zelen√° ƒç√°ra rulez! üéâ"
                return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** V√Ωraz se neaplikoval, nƒõco smrd√≠! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", history, 0

        async def toggle_camera_stream():
            status.value = "**Stav:** Kamera se bud√≠! üì∑"
            return gr.update(visible=True)

        async def run_lipsync(video_path: str, audio_path: str, mode: str, history: List[Dict], gallery: List[str]):
            if not video_path or not audio_path or not Path(video_path).exists() or not Path(audio_path).exists():
                status.value = "**Stav:** Video nebo zvuk chyb√≠, to je fiasko! üìπüéµ"
                return None, [], "‚ùó Nahraj video a zvuk!", history, 0
            progress_bar.value = 50
            try:
                normalized_audio = audio_processor.normalize_audio(audio_path)
                output_path = config.OUTPUT_DIR / get_next_output_filename("mp4")
                lipsync_engine.generate_lipsync(video_path, normalized_audio, output_path)
                history.append({"action": "lipsync", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** Lipsync hotov, mluv√≠≈° jak prof√≠k! üéâ"
                return output_path, gallery, "‚úÖ Lipsync dokonƒçen!", history, 100
            except Exception as e:
                status.value = "**Stav:** Lipsync se zasekl! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", history, 0

        async def run_upscale(image_path: str, model: str, factor: int, batch_mode: bool, files: List[str], history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku nezvƒõt≈°√≠≈° nic, g√©nius! üì∑"
                return None, [], "‚ùó Nahraj obr√°zek!", history, 0
            progress_bar.value = 50
            try:
                if batch_mode and files:
                    output_paths = []
                    for img_path in files:
                        if Path(img_path).suffix in [".jpg", ".png"]:
                            result = upscaler.upscale_image(img_path, model_name=model, scale=factor, device="cuda" if torch.cuda.is_available() else "cpu")
                            output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                            cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                            output_paths.append(output_path)
                            gallery.append(output_path)
                    history.append({"action": "batch_zvƒõt≈°it", "output": output_paths})
                    status.value = "**Stav:** Hromadn√© zvƒõt≈°en√≠ dokonƒçeno! üéâ"
                    return output_paths[0], gallery, "‚úÖ Batch zvƒõt≈°en√≠ hotovo!", history, 100
                else:
                    result = upscaler.upscale_image(image_path, model_name=model, scale=factor, device="cuda" if torch.cuda.is_available() else "cpu")
                    output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                    cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                    history.append({"action": "zvƒõt≈°it", "output": output_path})
                    gallery.append(output_path)
                    status.value = "**Stav:** Zvƒõt≈°eno, pixely v ext√°zi! üéâ"
                    return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** Zvƒõt≈°en√≠ se podƒõlalo, asi m√°≈° malou GPU! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", history, 0

        async def run_segmentation(image_path: str, mode: str, prompt: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists() or not prompt:
                status.value = "**Stav:** Obr√°zek nebo popis chyb√≠, to je trapas! üì∑"
                return None, [], "‚ùó Nahraj obr√°zek a popis!", history, 0
            progress_bar.value = 50
            try:
                if mode == "Odstranit pozad√≠":
                    result = segmenter.text_guided_segmentation(image_path, prompt)
                    output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                    cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                    history.append({"action": "segmentace", "output": output_path})
                    gallery.append(output_path)
                    status.value = "**Stav:** Pozad√≠ pryƒç, ƒçist√Ω styl! üéâ"
                    return output_path, gallery, result["message"], history, 100
                elif mode == "Rozmazat pozad√≠":
                    output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                    segmenter.blur_background(image_path, output_path, blur_strength=21)
                    history.append({"action": "rozmazat_pozad√≠", "output": output_path})
                    gallery.append(output_path)
                    status.value = "**Stav:** Pozad√≠ rozmazan√Ω, jako po t≈ôech pivech! üéâ"
                    return output_path, gallery, "‚úÖ Rozmaz√°n√≠ dokonƒçeno!", history, 100
            except Exception as e:
                status.value = "**Stav:** Segmentace se zasekla! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", history, 0

        async def separate_stems(audio_path: str, stems: List[str], history: List[Dict], gallery: List[str]):
            if not audio_path or not Path(audio_path).exists() or not stems:
                status.value = "**Stav:** Zvuk nebo stopy chyb√≠, to je ticho! üéµ"
                return None, [], "", "‚ùó Nahraj zvuk a stopy!", history, 0
            progress_bar.value = 50
            try:
                result = audio_processor.separate_audio_demucs(audio_path, stems)
                output_paths = []
                for stem, path in result["output_paths"].items():
                    new_path = config.OUTPUT_DIR / get_next_output_filename("wav")
                    os.rename(path, new_path)
                    output_paths.append(str(new_path))
                history.append({"action": "separovat_stopy", "output": output_paths})
                status.value = "**Stav:** Stopy separov√°ny, v≈°e hraje! üéâ"
                return None, [], result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** Separace stop selhala, v≈°e je jeden chaos! üòµ"
                return None, [], f"‚ùó Chyba: {e}", history, 0

        async def apply_audio_effect(audio_path: str, effect: str, history: List[Dict], gallery: List[str]):
            if not audio_path or not Path(audio_path).exists():
                status.value = "**Stav:** Bez zvuku ≈æ√°dn√Ω efekt, logika! üéµ"
                return None, [], "", history, 0
            progress_bar.value = 50
            try:
                # Simulace aplikace efektu (v re√°lu bys pou≈æil audio_processor.apply_effect)
                output_path = config.OUTPUT_DIR / get_next_output_filename("wav")
                audio_processor.normalize_audio(audio_path)  # Placeholder
                history.append({"action": f"aplikovat_efekt_{effect.lower()}", "output": output_path})
                status.value = f"**Stav:** Efekt {effect} aplikov√°n, zn√≠ to jak z Grammy! üéâ"
                return output_path, [], "‚úÖ Efekt aplikov√°n!", history, 100
            except Exception as e:
                status.value = "**Stav:** Efekt selhal, asi ≈°patn√Ω mixpult! üòµ"
                return None, [], f"‚ùó Chyba: {e}", history, 0

        async def transcribe_audio(audio_path: str, history: List[Dict], gallery: List[str]):
            if not audio_path or not Path(audio_path).exists():
                status.value = "**Stav:** Bez zvuku ≈æ√°dn√Ω p≈ôepis, logika! üéµ"
                return None, [], "", "‚ùó Nahraj zvuk!", history, 0
            progress_bar.value = 50
            try:
                result = audio_processor.transcribe_audio(audio_path)
                history.append({"action": "p≈ôepsat_zvuk", "output": result["output_path"]})
                status.value = "**Stav:** P≈ôepis hotov, text je tv≈Øj! üéâ"
                return None, [], result["transcription"], history, 100
            except Exception as e:
                status.value = "**Stav:** P≈ôepis selhal, asi ≈°patn√Ω mikrofon! üòµ"
                return None, [], f"‚ùó Chyba: {e}", history, 0

        async def run_artifact_analysis(image_path: str, compare_image: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku ≈æ√°dn√° anal√Ωza, Sherlocku! üì∑"
                return None, [], "‚ùó Nahraj obr√°zek!", history, 0
            progress_bar.value = 50
            try:
                result = forensic_tools.analyze_jpeg_artifacts(image_path)
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                history.append({"action": "analyzovat_artefakty", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** Artefakty analyzov√°ny, jsi detektiv! üéâ"
                return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** Anal√Ωza se zasekla! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", history, 0

        async def run_ela_analysis(image_path: str, compare_image: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku ≈æ√°dn√° ELA, Sherlocku! üì∑"
                return None, [], "‚ùó Nahraj obr√°zek!", history, 0
            progress_bar.value = 50
            try:
                result = forensic_tools.error_level_analysis(image_path)
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                cv2.imwrite(str(output_path), cv2.cvtColor(result["image"], cv2.COLOR_RGB2BGR))
                history.append({"action": "ela_anal√Ωza", "output": output_path})
                gallery.append(output_path)
                status.value = "**Stav:** ELA hotov√°, manipulace odhalena! üéâ"
                return output_path, gallery, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** ELA se zasekla! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", history, 0

        async def run_deepfake_detection(image_path: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku ≈æ√°dn√Ω deepfake lov, Sherlocku! üì∑"
                return None, [], None, "‚ùó Nahraj obr√°zek!", history, 0
            progress_bar.value = 50
            try:
                result = forensic_tools.detect_deepfake(image_path)
                # NOV√â: Deepfake sk√≥re graf
                score = result.get("score", 0.5)
                df = pd.DataFrame({"Kategorie": ["Deepfake pravdƒõpodobnost"], "Sk√≥re": [score]})
                fig = px.bar(df, x="Kategorie", y="Sk√≥re", title="Deepfake Sk√≥re", range_y=[0, 1])
                history.append({"action": "detekovat_deepfake", "output": None})
                status.value = "**Stav:** Deepfake anal√Ωza hotov√°, pravda venku! üéâ"
                return None, gallery, fig, result["message"], history, 100
            except Exception as e:
                status.value = "**Stav:** Deepfake detekce selhala! üòµ"
                return None, gallery, None, f"‚ùó Chyba: {e}", history, 0

        async def run_exif_extraction(image_path: str, history: List[Dict], gallery: List[str]):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku ≈æ√°dn√© EXIF, logika! üì∑"
                return None, [], "", "‚ùó Nahraj obr√°zek!", history, 0
            progress_bar.value = 50
            try:
                result = forensic_tools.extract_exif(image_path)
                exif_text = "\n".join([f"{k}: {v}" for k, v in result.items()]) if result.get("error") is None else result["error"]
                history.append({"action": "extrahovat_exif", "output": None})
                status.value = "**Stav:** EXIF vyta≈æen, v≈°echno v√≠me! üéâ"
                return None, gallery, exif_text, "‚úÖ EXIF extrahov√°na!", history, 100
            except Exception as e:
                status.value = "**Stav:** EXIF extrakce selhala, metadata se schovala! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", "‚ùó EXIF selhal!", history, 0

        async def sdxl_text2img(prompt, negative_prompt, steps, guidance):
            if not prompt:
                status.value = "**Stav:** Bez popisu nic negeneruju, g√©nius! üìù"
                return None, [], "‚ùó Zadej popis!", action_history, 0
            progress_bar.value = 50
            try:
                result = sdxl_runner.generate_text2img(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    num_steps=int(steps),
                    guidance_scale=guidance
                )
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                result.save(output_path)
                action_history.append({"action": "sdxl_text2img", "output": output_path})
                output_gallery.append(output_path)
                status.value = "**Stav:** SDXL vygeneroval umƒõleck√Ω kousek! üéâ"
                return result, output_gallery, "‚úÖ Obr√°zek hotov!", action_history, 100
            except Exception as e:
                status.value = "**Stav:** SDXL se zasekl, asi ≈°patn√Ω prompt! üòµ"
                return None, output_gallery, f"‚ùó Chyba: {e}", action_history, 0

        async def sdxl_img2img(image_path: str, prompt, strength, negative_prompt, steps, guidance):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku ≈æ√°dn√Ω img2img, logika! üì∑"
                return None, [], "‚ùó Nahraj obr√°zek!", action_history, 0
            progress_bar.value = 50
            try:
                with Image.open(image_path) as img:
                    result = sdxl_runner.generate_img2img(
                        input_image=img,
                        prompt=prompt,
                        strength=strength,
                        negative_prompt=negative_prompt,
                        num_steps=int(steps),
                        guidance_scale=guidance
                    )
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                result.save(output_path)
                action_history.append({"action": "sdxl_img2img", "output": output_path})
                output_gallery.append(output_path)
                status.value = "**Stav:** SDXL img2img hotov, jsi umƒõlec! üéâ"
                return result, output_gallery, "‚úÖ Obr√°zek hotov!", action_history, 100
            except Exception as e:
                status.value = "**Stav:** SDXL img2img selhal, asi ≈°patn√Ω den! üòµ"
                return None, output_gallery, f"‚ùó Chyba: {e}", action_history, 0

        def sdxl_save(image, prompt):
            if image is None:
                status.value = "**Stav:** ≈Ω√°dn√Ω obr√°zek, co chce≈° ukl√°dat? üì∑"
                return "‚ùó Nic k ulo≈æen√≠!"
            return save_to_history(image, "sdxl", prompt)

        async def flux_text2img(prompt, negative_prompt, steps, guidance, sampler, lora_weight, width, height):
            if not prompt:
                status.value = "**Stav:** Bez popisu nic negeneruju, logika! üìù"
                return None, [], "‚ùó Zadej popis!", action_history, 0
            progress_bar.value = 50
            try:
                result = flux_runner.generate_text2img(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    num_steps=int(steps),
                    guidance_scale=guidance,
                    width=int(width),
                    height=int(height),
                    sampler=sampler,
                    lora_weight=lora_weight
                )
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                result.save(output_path)
                action_history.append({"action": "flux_text2img", "output": output_path})
                output_gallery.append(output_path)
                status.value = "**Stav:** Flux vygeneroval masterpiece! üéâ"
                return result, output_gallery, "‚úÖ Obr√°zek hotov!", action_history, 100
            except Exception as e:
                status.value = "**Stav:** Flux se zasekl, asi ≈°patn√Ω prompt! üòµ"
                return None, output_gallery, f"‚ùó Chyba: {e}", action_history, 0

        async def flux_img2img(image_path: str, prompt, strength, negative_prompt, steps, guidance, sampler, lora_weight, width, height):
            if not image_path or not Path(image_path).exists():
                status.value = "**Stav:** Bez obr√°zku ≈æ√°dn√Ω img2img, g√©nius! üì∑"
                return None, [], "‚ùó Nahraj obr√°zek!", action_history, 0
            progress_bar.value = 50
            try:
                with Image.open(image_path) as img:
                    result = flux_runner.generate_img2img(
                        input_image=img,
                        prompt=prompt,
                        strength=strength,
                        negative_prompt=negative_prompt,
                        num_steps=int(steps),
                        guidance_scale=guidance,
                        width=int(width),
                        height=int(height),
                        sampler=sampler,
                        lora_weight=lora_weight
                    )
                output_path = config.OUTPUT_DIR / get_next_output_filename("png")
                result.save(output_path)
                action_history.append({"action": "flux_img2img", "output": output_path})
                output_gallery.append(output_path)
                status.value = "**Stav:** Flux img2img hotov, jsi Picasso! üéâ"
                return result, output_gallery, "‚úÖ Obr√°zek hotov!", action_history, 100
            except Exception as e:
                status.value = "**Stav:** Flux img2img selhal, asi ≈°patn√Ω den! üòµ"
                return None, output_gallery, f"‚ùó Chyba: {e}", action_history, 0

        def flux_save(image, prompt):
            if image is None:
                status.value = "**Stav:** ≈Ω√°dn√Ω obr√°zek, co chce≈° ukl√°dat? üì∑"
                return "‚ùó Nic k ulo≈æen√≠!"
            return save_to_history(image, "flux", prompt)

        async def run_export(preview_output: str, format: str, fps: int, export_name: str, 
                            history: List[Dict], gallery: List[str]):
            if not preview_output:
                status.value = "**Stav:** Nic k exportu, to je pr√°zdno! üì∑"
                return None, [], "‚ùó Nic k exportu!", history, 0
            progress_bar.value = 50
            try:
                output_name = export_name or get_next_output_filename(format.lower())
                if format == "MP4":
                    output_path = video_exporter.export_to_mp4(preview_output, output_name=output_name, fps=fps)
                elif format == "GIF":
                    output_path = video_exporter.export_to_gif(preview_output, output_name=output_name, fps=fps)
                else:
                    output_path = video_exporter.export_to_png_sequence(preview_output, output_dir_name=output_name)
                if output_path and Path(output_path).exists():
                    history.append({"action": "export", "output": output_path})
                    gallery.append(output_path)
                    status.value = "**Stav:** Export hotov, jsi ≈°√©f! üéâ"
                    return None, gallery, f"‚úÖ Export dokonƒçen: {output_path}", history, 100
                status.value = "**Stav:** Export selhal, nƒõco smrd√≠! üòµ"
                return None, gallery, "‚ùó Export selhal!", history, 100
            except Exception as e:
                status.value = "**Stav:** Export se zasekl! üòµ"
                return None, gallery, f"‚ùó Chyba: {e}", history, 0

        def show_history(history: List[Dict], filter_type: str) -> str:
            if not history:
                status.value = "**Stav:** Historie je pr√°zdn√°, nic jsi nedƒõlal! üìú"
                return "‚ùó ≈Ω√°dn√© akce!"
            filtered_history = history if filter_type == "V≈°e" else [h for h in history if filter_type.lower() in h["action"].lower()]
            return "\n".join([f"{i+1}. {action['action']}: {action['output'] or '≈Ω√°dn√Ω v√Ωstup'}" for i, action in enumerate(filtered_history)])

        def save_project(history: List[Dict]):
            try:
                project_path = config.OUTPUT_DIR / "projects" / "project.json"
                project_path.parent.mkdir(exist_ok=True)
                with open(project_path, "w", encoding="utf-8") as f:
                    json.dump(history, f, indent=2, ensure_ascii=False)
                history.append({"action": "ulo≈æit_projekt", "output": str(project_path)})
                status.value = "**Stav:** Projekt ulo≈æen, jsi zorganizovan√Ω! üéâ"
                return None, [], f"‚úÖ Projekt ulo≈æen: {project_path}", history, 100
            except Exception as e:
                status.value = "**Stav:** Ukl√°d√°n√≠ projektu selhalo, chaos vl√°dne! üòµ"
                return None, [], f"‚ùó Chyba: {e}", history, 0

        def load_project(history: List[Dict]):
            try:
                project_path = config.OUTPUT_DIR / "projects" / "project.json"
                if not project_path.exists():
                    status.value = "**Stav:** Projekt neexistuje, co to hled√°≈°? üìú"
                    return None, [], "‚ùó Projekt neexistuje!", history, 0
                with open(project_path, "r", encoding="utf-8") as f:
                    loaded_history = json.load(f)
                history.clear()
                history.extend(loaded_history)
                status.value = "**Stav:** Projekt naƒçten, jdeme d√°l! üéâ"
                return None, [], f"‚úÖ Projekt naƒçten: {project_path}", history, 100
            except Exception as e:
                status.value = "**Stav:** Naƒç√≠t√°n√≠ projektu selhalo, nƒõco smrd√≠! üòµ"
                return None, [], f"‚ùó Chyba: {e}", history, 0

        def undo_action(history: List[Dict], gallery: List[str]):
            if history:
                last_action = history.pop()
                if last_action["output"] in gallery:
                    gallery.remove(last_action["output"])
                status.value = "**Stav:** Akce vr√°cena, ƒças se vr√°til! ‚Ü©Ô∏è"
                return None, gallery, f"‚úÖ Vr√°cena akce: {last_action['action']}", history, 100
            status.value = "**Stav:** Nic k vr√°cen√≠, historie je pr√°zdn√°! üìú"
            return None, [], "‚ùó Nic k vr√°cen√≠!", history, 0

        def download_youtube(url: str, output_path: str):
            ydl_opts = {
                "outtmpl": output_path,
                "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
                "merge_output_format": "mp4",
                "quiet": True
            }
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])
            logger.info(f"‚úÖ YouTube video sta≈æeno: {output_path}")

        # P≈ôi≈ôazen√≠ akc√≠
        tabs.select(fn=update_active_tab, inputs=None, outputs=active_tab)
        source_selector.change(
            fn=update_source_selector,
            inputs=source_selector,
            outputs=[youtube_url, batch_dir]
        )
        lipsync_mode.change(
            fn=update_phoneme_timeline,
            inputs=[lipsync_mode, input_files],
            outputs=phoneme_timeline
        )
        upload_button.click(
            fn=upload_and_preview,
            inputs=[input_files, source_selector, youtube_url, batch_dir, action_history, stem_selector, output_gallery],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar, input_files, transcription_output, metadata_display]
        )
        generate_caption_button.click(
            fn=generate_deepdanbooru_caption,
            inputs=[input_files],
            outputs=[status]
        )
        clear_button.click(
            fn=clear_inputs,
            inputs=[action_history, output_gallery],
            outputs=[input_files, youtube_url, batch_dir, preview_output, gallery_output, status, action_history, progress_bar, input_files, transcription_output, metadata_display]
        )
        detect_face_button.click(
            fn=detect_face,
            inputs=[input_files, action_history, output_gallery],
            outputs=[face_output, gallery_output, status, action_history, progress_bar]
        )
        face_swap_button.click(
            fn=run_face_swap,
            inputs=[input_files, face_swap_target, action_history, output_gallery],
            outputs=[face_output, gallery_output, status, action_history, progress_bar]
        )
        apply_expression_button.click(
            fn=apply_expression,
            inputs=[input_files, expression_slider, expression_model, action_history, output_gallery],
            outputs=[face_output, gallery_output, status, action_history, progress_bar]
        )
        toggle_camera.click(
            fn=toggle_camera_stream,
            inputs=[],
            outputs=[preview_output]
        )
        lipsync_button.click(
            fn=run_lipsync,
            inputs=[input_files, input_files, lipsync_mode, action_history, output_gallery],
            outputs=[lipsync_output, gallery_output, status, action_history, progress_bar]
        )
        upscale_button.click(
            fn=run_upscale,
            inputs=[input_files, upscale_model, upscale_factor, batch_upscale, input_files, action_history, output_gallery],
            outputs=[upscale_output, gallery_output, status, action_history, progress_bar]
        )
        segment_button.click(
            fn=run_segmentation,
            inputs=[input_files, segment_mode, segment_prompt, action_history, output_gallery],
            outputs=[segment_output, gallery_output, status, action_history, progress_bar]
        )
        separate_stems_button.click(
            fn=separate_stems,
            inputs=[input_files, stem_selector, action_history, output_gallery],
            outputs=[audio_output, gallery_output, status, action_history, progress_bar]
        )
        transcribe_button.click(
            fn=transcribe_audio,
            inputs=[input_files, action_history, output_gallery],
            outputs=[audio_output, gallery_output, transcription_output, status, action_history, progress_bar]
        )
        apply_effect_button.click(
            fn=apply_audio_effect,
            inputs=[input_files, audio_effect, action_history, output_gallery],
            outputs=[audio_output, gallery_output, status, action_history, progress_bar]
        )
        forensic_button.click(
            fn=run_artifact_analysis,
            inputs=[input_files, compare_image, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, status, action_history, progress_bar]
        )
        ela_button.click(
            fn=run_ela_analysis,
            inputs=[input_files, compare_image, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, status, action_history, progress_bar]
        )
        deepfake_button.click(
            fn=run_deepfake_detection,
            inputs=[input_files, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, deepfake_plot, status, action_history, progress_bar]
        )
        exif_button.click(
            fn=run_exif_extraction,
            inputs=[input_files, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, exif_output, status, action_history, progress_bar]
        )
        report_button.click(
            fn=lambda x, h, g: (None, g, "üìú PDF zpr√°va generov√°na!", h, 100),  # Placeholder pro PDF generov√°n√≠
            inputs=[input_files, action_history, output_gallery],
            outputs=[forensic_output, gallery_output, status, action_history, progress_bar]
        )
        sdxl_text2img_button.click(
            fn=sdxl_text2img,
            inputs=[sdxl_prompt, sdxl_negative_prompt, sdxl_steps, sdxl_guidance],
            outputs=[sdxl_output, gallery_output, status, action_history, progress_bar]
        )
        sdxl_img2img_button.click(
            fn=sdxl_img2img,
            inputs=[input_files, sdxl_prompt, sdxl_strength, sdxl_negative_prompt, sdxl_steps, sdxl_guidance],
            outputs=[sdxl_output, gallery_output, status, action_history, progress_bar]
        )
        sdxl_save_button.click(
            fn=sdxl_save,
            inputs=[sdxl_output, sdxl_prompt],
            outputs=[status]
        )
        flux_text2img_button.click(
            fn=flux_text2img,
            inputs=[flux_prompt, flux_negative_prompt, flux_steps, flux_guidance, flux_sampler, flux_lora_weight, flux_width, flux_height],
            outputs=[flux_output, gallery_output, status, action_history, progress_bar]
        )
        flux_img2img_button.click(
            fn=flux_img2img,
            inputs=[input_files, flux_prompt, flux_strength, flux_negative_prompt, flux_steps, flux_guidance, flux_sampler, flux_lora_weight, flux_width, flux_height],
            outputs=[flux_output, gallery_output, status, action_history, progress_bar]
        )
        flux_save_button.click(
            fn=flux_save,
            inputs=[flux_output, flux_prompt],
            outputs=[status]
        )
        export_button.click(
            fn=run_export,
            inputs=[preview_output, export_format, export_fps, export_name, action_history, output_gallery],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar]
        )
        save_project_button.click(
            fn=save_project,
            inputs=[action_history],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar]
        )
        load_project_button.click(
            fn=load_project,
            inputs=[action_history],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar]
        )
        undo_button.click(
            fn=undo_action,
            inputs=[action_history, output_gallery],
            outputs=[preview_output, gallery_output, status, action_history, progress_bar]
        )
        show_history_button.click(
            fn=show_history,
            inputs=[action_history, history_filter],
            outputs=[history_display]
        )
        refresh_history_button.click(
            fn=lambda: get_history_images(),
            inputs=[],
            outputs=[history_gallery]
        )
        export_history_csv.click(
            fn=export_history_to_csv,
            inputs=[action_history],
            outputs=[status]
        )
        # NOV√â: Rychl√© akce
        quick_detect.click(
            fn=detect_face,
            inputs=[input_files, action_history, output_gallery],
            outputs=[face_output, gallery_output, status, action_history, progress_bar]
        )
        quick_upscale.click(
            fn=run_upscale,
            inputs=[input_files, upscale_model, upscale_factor, batch_upscale, input_files, action_history, output_gallery],
            outputs=[upscale_output, gallery_output, status, action_history, progress_bar]
        )
        quick_segment.click(
            fn=run_segmentation,
            inputs=[input_files, segment_mode, segment_prompt, action_history, output_gallery],
            outputs=[segment_output, gallery_output, status, action_history, progress_bar]
        )

    logger.info("üéâ GUI je ready! Otev≈ôi http://0.0.0.0:7860 a rozpoutej pixelov√© peklo! üî•")
    return app

if __name__ == "__main__":
    try:
        app = create_gui()
        app.launch(
            inbrowser=True,
            server_name="0.0.0.0",
            server_port=7860,
            max_threads=10,
            queue_max_size=100,
            show_error=True
        )
        logger.info("üöÄ GUI bƒõ≈æ√≠! Jdi na http://0.0.0.0:7860 a tvo≈ô, nebo zem≈ôi! üî•")
    except Exception as e:
        logger.error(f"üí• GUI se zhroutilo: {e}. To je masakr, k√°mo! üòµ")
        input("Stiskni kl√°vesu a zkus to znova... Pixely ƒçekaj√≠! üòà")