# core/face_swapper.py
"""
FaceSwapper â€“ vymÄ›nÃ­ tvÅ¯j ksicht, aÅ¾ se budeÅ¡ ptÃ¡t, kdo je ten frajer v zrcadle! ğŸ˜
RetinaFace detekuje obliÄeje, GAN je mÄ›nÃ­. RealistickÃ½ blending a animace jako bonus! ğŸ˜ˆ
"""
import logging
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
import torch
from typing import Dict, List, Optional, Callable
from main import get_next_output_filename
from utils.helpers import Config
from retinaface_loader import RetinaFaceDetector
import imageio

logger = logging.getLogger(__name__)

class FaceSwapper:
    def __init__(self):
        """Inicializuje swapper obliÄejÅ¯. Ksichty se chystajÃ­ na vÃ½mÄ›nu! ğŸ”„"""
        self.config = Config()
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.retinaface = RetinaFaceDetector()
        self.swap_model = None
        self.load_swap_model()
        logger.info(f"âœ… FaceSwapper inicializovÃ¡n na {self.device}. ObliÄeje ÄekÃ¡ divokÃ¡ jÃ­zda! ğŸ˜ˆ")

    def load_swap_model(self):
        """NaÄte GAN model pro vÃ½mÄ›nu obliÄejÅ¯. DeepFaceLab by zÃ¡vidÄ›l! ğŸ¦"""
        try:
            # Placeholder pro naÄtenÃ­ GAN modelu (napÅ™. DeepFaceLab nebo SimSwap)
            self.swap_model = lambda src, tgt, landmarks: self._simulate_face_swap(src, tgt, landmarks)
            logger.info("âœ… Swap model naÄten. ObliÄeje se budou mÄ›nit jako ponoÅ¾ky! ğŸ§¦")
        except Exception as e:
            logger.error(f"âŒ NaÄÃ­tÃ¡nÃ­ swap modelu selhalo: {e}. Ksichty zÅ¯stanou pÅ¯vodnÃ­! ğŸ˜£")
            raise

    def _simulate_face_swap(self, source_img: np.ndarray, target_img: np.ndarray, 
                           landmarks: Dict) -> np.ndarray:
        """Simuluje vÃ½mÄ›nu obliÄeje. V reÃ¡lu by tady byl GAN! ğŸ˜œ"""
        try:
            # Simulace: vezme obliÄej ze zdroje a pÅ™ekopÃ­ruje ho na cÃ­l
            bbox = landmarks["bbox"]
            x, y, w, h = [int(v) for v in bbox]
            face = source_img[y:y+h, x:x+w]
            face_resized = cv2.resize(face, (w, h))
            
            # ZÃ¡kladnÃ­ blending (v reÃ¡lu bys pouÅ¾il GAN vÃ½stup)
            result = target_img.copy()
            result[y:y+h, x:x+w] = face_resized
            
            # Seamless cloning pro realistickÃ½ vÃ½sledek
            mask = np.ones_like(face_resized) * 255
            center = (x + w // 2, y + h // 2)
            result = cv2.seamlessClone(face_resized, result, mask, center, cv2.NORMAL_CLONE)
            
            # BarevnÃ¡ korekce
            result = self._color_correction(result, target_img, landmarks)
            return result
        except Exception as e:
            logger.error(f"âŒ Simulace vÃ½mÄ›ny selhala: {e}. ObliÄej zÅ¯stal na svÃ©m mÃ­stÄ›! ğŸ˜£")
            return target_img

    def _color_correction(self, swapped_img: np.ndarray, target_img: np.ndarray, 
                         landmarks: Dict) -> np.ndarray:
        """UpravÃ­ barvy pro realistickÃ½ blending. Pixely se sladÃ­! ğŸ¨"""
        try:
            bbox = landmarks["bbox"]
            x, y, w, h = [int(v) for v in bbox]
            swapped_face = swapped_img[y:y+h, x:x+w]
            target_face = target_img[y:y+h, x:x+w]
            
            # PÅ™izpÅ¯sobenÃ­ prÅ¯mÄ›rnÃ©ho jasu a kontrastu
            swapped_hsv = cv2.cvtColor(swapped_face, cv2.COLOR_RGB2HSV)
            target_hsv = cv2.cvtColor(target_face, cv2.COLOR_RGB2HSV)
            swapped_hsv[:, :, 2] = np.clip(swapped_hsv[:, :, 2] * 
                                         (np.mean(target_hsv[:, :, 2]) / np.mean(swapped_hsv[:, :, 2])), 
                                         0, 255).astype(np.uint8)
            swapped_face = cv2.cvtColor(swapped_hsv, cv2.COLOR_HSV2RGB)
            
            swapped_img[y:y+h, x:x+w] = swapped_face
            return swapped_img
        except Exception as e:
            logger.error(f"âŒ BarevnÃ¡ korekce selhala: {e}. Barvy jsou divokÃ½! ğŸ˜£")
            return swapped_img

    def detect_faces(self, img: np.ndarray) -> List[Dict]:
        """Detekuje obliÄeje a klÃ­ÄovÃ© body pomocÃ­ RetinaFace. Sherlock by breÄel zÃ¡vistÃ­! ğŸ•µï¸â€â™‚ï¸"""
        try:
            faces = self.retinaface.detect(img)
            if not faces:
                logger.warning("âš ï¸ Å½Ã¡dnÃ© obliÄeje nenalezeny! Je to fotka kamenÃ­? ğŸª¨")
                return []
            logger.info(f"âœ… Nalezeno {len(faces)} obliÄejÅ¯. VÃ½mÄ›na mÅ¯Å¾e zaÄÃ­t! ğŸ˜")
            return faces
        except Exception as e:
            logger.error(f"âŒ Detekce obliÄejÅ¯ selhala: {e}. ObliÄeje se schovaly! ğŸ˜£")
            return []

    def swap_faces(self, 
                  source_image_path: str, 
                  target_image_path: str, 
                  create_gif: bool = False, 
                  output_format: str = "png", 
                  quality: int = 95, 
                  progress_callback: Optional[Callable[[int], None]] = None) -> Dict:
        """VymÄ›nÃ­ obliÄej ze zdrojovÃ©ho obrÃ¡zku na cÃ­lovÃ½. Ksichty se mÄ›nÃ­ jako v cirkusu! ğŸª"""
        if not Path(source_image_path).exists() or not Path(target_image_path).exists():
            logger.error("â— Jeden z obrÃ¡zkÅ¯ nenalezen! Kde jsou ty ksichty? ğŸ–¼ï¸")
            return {"image": None, "message": "â— ObrÃ¡zek nenalezen!"}

        try:
            # NaÄtenÃ­ obrÃ¡zkÅ¯
            source_img = cv2.imread(source_image_path)
            target_img = cv2.imread(target_image_path)
            if source_img is None or target_img is None:
                raise ValueError("Nelze naÄÃ­st obrÃ¡zky! Jsou to vÅ¯bec obrÃ¡zky? ğŸ˜¤")
            source_img_rgb = cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB)
            target_img_rgb = cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB)
            if progress_callback:
                progress_callback(10)  # 10% za naÄtenÃ­

            # Detekce obliÄejÅ¯
            source_faces = self.detect_faces(source_img_rgb)
            target_faces = self.detect_faces(target_img_rgb)
            if not source_faces or not target_faces:
                return {"image": None, "message": "â— Å½Ã¡dnÃ© obliÄeje nenalezeny v jednom z obrÃ¡zkÅ¯!"}
            if progress_callback:
                progress_callback(30)  # 30% po detekci

            # VÃ½mÄ›na prvnÃ­ho obliÄeje (v reÃ¡lu bys mohl zpracovat vÃ­ce)
            source_face = source_faces[0]
            target_face = target_faces[0]
            swapped_img = self.swap_model(source_img_rgb, target_img_rgb, target_face)
            if progress_callback:
                progress_callback(70)  # 70% po vÃ½mÄ›nÄ›

            # UloÅ¾enÃ­ vÃ½stupu
            output_path = self.config.OUTPUT_DIR / get_next_output_filename(output_format)
            if create_gif:
                # VytvoÅ™enÃ­ animace pÅ™echodu
                gif_path = self.config.OUTPUT_DIR / get_next_output_filename("gif")
                self._create_transition_gif(target_img_rgb, swapped_img, gif_path)
                logger.info(f"âœ… Animace vÃ½mÄ›ny uloÅ¾ena: {gif_path}")
                output_path = gif_path
            else:
                if output_format == "png":
                    cv2.imwrite(str(output_path), cv2.cvtColor(swapped_img, cv2.COLOR_RGB2BGR))
                elif output_format == "jpg":
                    cv2.imwrite(str(output_path), cv2.cvtColor(swapped_img, cv2.COLOR_RGB2BGR), 
                               [int(cv2.IMWRITE_JPEG_QUALITY), quality])
                else:
                    raise ValueError(f"NepodporovanÃ½ formÃ¡t: {output_format}. Vyber png nebo jpg! ğŸ˜¤")
            
            if progress_callback:
                progress_callback(100)  # 100% po uloÅ¾enÃ­
            
            logger.info(f"âœ… ObliÄej vymÄ›nÄ›n, vÃ½stup: {output_path}")
            return {
                "image": swapped_img,
                "message": f"âœ… ObliÄej vymÄ›nÄ›n, uloÅ¾eno jako {output_path}"
            }
        except Exception as e:
            logger.error(f"âŒ VÃ½mÄ›na obliÄeje selhala: {e}. Ksichty zÅ¯staly na svÃ©m mÃ­stÄ›! ğŸ˜£")
            return {"image": None, "message": f"â— Chyba: {e}"}

    def _create_transition_gif(self, original_img: np.ndarray, swapped_img: np.ndarray, 
                              output_path: Path):
        """VytvoÅ™Ã­ GIF s plynulÃ½m pÅ™echodem mezi obliÄeji. Divadlo v pixelech! ğŸ¬"""
        try:
            frames = []
            num_frames = 10
            for i in range(num_frames):
                alpha = i / (num_frames - 1)
                blended = cv2.addWeighted(original_img, 1 - alpha, swapped_img, alpha, 0.0)
                frames.append(Image.fromarray(blended))
            
            frames[0].save(output_path, save_all=True, append_images=frames[1:], duration=100, loop=0)
            logger.info(f"âœ… GIF vytvoÅ™en: {output_path}")
        except Exception as e:
            logger.error(f"âŒ VytvoÅ™enÃ­ GIFu selhalo: {e}. Å½Ã¡dnÃ¡ animace! ğŸ˜£")

    def swap_batch_faces(self, 
                        source_image_path: str, 
                        target_image_paths: List[str], 
                        create_gif: bool = False, 
                        output_format: str = "png", 
                        quality: int = 95, 
                        progress_callback: Optional[Callable[[int], None]] = None) -> List[Dict]:
        """VymÄ›nÃ­ obliÄej ze zdrojovÃ©ho obrÃ¡zku na vÃ­ce cÃ­lovÃ½ch. Batch swapping, ksichty v masovce! ğŸ“š"""
        if not Path(source_image_path).exists():
            logger.error("â— ZdrojovÃ½ obrÃ¡zek nenalezen! Kde je ten hlavnÃ­ ksicht? ğŸ–¼ï¸")
            return [{"image": None, "message": "â— ZdrojovÃ½ obrÃ¡zek nenalezen!"}]
        if not target_image_paths:
            logger.error("â— Å½Ã¡dnÃ© cÃ­lovÃ© obrÃ¡zky! Batch je prÃ¡zdnÃ½ jako hospoda o pÃ¡tÃ© rÃ¡no! ğŸº")
            return [{"image": None, "message": "â— Å½Ã¡dnÃ© cÃ­lovÃ© obrÃ¡zky!"}]

        results = []
        total_images = len(target_image_paths)
        
        for i, target_image_path in enumerate(target_image_paths):
            if not Path(target_image_path).exists():
                logger.error(f"â— CÃ­lovÃ½ obrÃ¡zek {target_image_path} nenalezen! PÅ™eskakuju...")
                results.append({"image": None, "message": f"â— ObrÃ¡zek {target_image_path} nenalezen!"})
                continue
            
            # VlastnÃ­ callback pro batch
            def batch_progress(step: int):
                if progress_callback:
                    progress = int((i / total_images) * 100 + (step / total_images))
                    progress_callback(min(progress, 100))  # OmezenÃ­ na 100%
            
            result = self.swap_faces(
                source_image_path=source_image_path,
                target_image_path=target_image_path,
                create_gif=create_gif,
                output_format=output_format,
                quality=quality,
                progress_callback=batch_progress
            )
            results.append(result)
        
        logger.info(f"âœ… Batch zpracovÃ¡n: {len(results)} obrÃ¡zkÅ¯, zdrojovÃ½ obliÄej vymÄ›nÄ›n")
        return results

if __name__ == "__main__":
    # TestovacÃ­ kÃ³d, aÅ¥ vidÃ­me, jak to mÄ›nÃ­ ksichty! ğŸ˜
    swapper = FaceSwapper()
    source_image = "source_face.jpg"
    target_images = ["target_face1.jpg", "target_face2.jpg"]
    
    # Test jednoho obrÃ¡zku
    result = swapper.swap_faces(
        source_image_path=source_image,
        target_image_path=target_images[0],
        create_gif=True,
        output_format="png",
        quality=90,
        progress_callback=lambda x: print(f"Progress: {x}%")
    )
    print(result["message"])
    
    # Test batch processing
    results = swapper.swap_batch_faces(
        source_image_path=source_image,
        target_image_paths=target_images,
        create_gif=False,
        output_format="jpg",
        quality=95,
        progress_callback=lambda x: print(f"Batch Progress: {x}%")
    )
    for res in results:
        print(res["message"])