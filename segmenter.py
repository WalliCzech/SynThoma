# core/segmenter.py
"""
Segmenter â€“ rozsekÃ¡ pozadÃ­ jako Å vejk svÃ­Äkovou! âœ‚ï¸
SAM a Grounding DINO v akci, aÅ¥ pixely breÄÃ­! ğŸ˜ˆ
"""
import logging
from typing import Dict
from pathlib import Path
import numpy as np
import cv2
from PIL import Image
import torch
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
from groundingdino_model import build_groundingdino
from utils.helpers import Config
from main import get_next_output_filename

logger = logging.getLogger(__name__)

class Segmenter:
    def __init__(self, use_grounding_dino: bool = False):
        """Inicializuje segmenter. PozadÃ­ pÅ¯jde pod nÅ¯Å¾! âœ‚ï¸"""
        self.config = Config()
        self.sam = None
        self.grounding_dino = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.load_sam()
        if use_grounding_dino:
            self.load_grounding_dino()
        else:
            logger.warning("âš ï¸ Grounding DINO je vypnutÃ½, SAM to zvlÃ¡dne sÃ¡m! ğŸ˜")
        
    def load_sam(self):
        """NaÄte SAM model. Å˜eÅ¾e pozadÃ­ jako profÃ­k! ğŸ”ª"""
        try:
            sam_checkpoint = Path("C:/wAllICzech/ai_models/Segmentation/sam_vit_h_4b8939.pth")
            if not sam_checkpoint.exists():
                raise FileNotFoundError(f"SAM checkpoint nenalezen: {sam_checkpoint}")
            model_type = "vit_h"
            sam = sam_model_registry[model_type](checkpoint=str(sam_checkpoint))
            sam.to(device=self.device)
            self.sam = SamAutomaticMaskGenerator(sam)
            logger.info("âœ… SAM model naÄten. PozadÃ­ nemÃ¡ Å¡anci! ğŸ˜ˆ")
        except Exception as e:
            logger.error(f"âŒ SAM se zasekl: {e}. Segmentace bez SAM je jak pivo bez pÄ›ny! ğŸº")
            raise

    def load_grounding_dino(self):
        """NaÄte Grounding DINO pro pÅ™esnÄ›jÅ¡Ã­ detekci. Sherlock by zÃ¡vidÄ›l! ğŸ•µï¸â€â™‚ï¸"""
        try:
            self.grounding_dino = build_groundingdino()
            logger.info("âœ… Grounding DINO naÄten. Detekce na steroidech! ğŸ’ª")
        except Exception as e:
            logger.error(f"âŒ Grounding DINO selhal: {e}. Jdeme bez nÄ›j, ale bude to divoÄina! ğŸŒªï¸")
            self.grounding_dino = None

    def text_guided_segmentation(self, image_path: str, text_prompt: str) -> Dict:
        """Segmentuje obrÃ¡zek podle textovÃ©ho popisu. PozadÃ­ pryÄ, nebo breÄÃ­! ğŸ˜­"""
        if not Path(image_path).exists():
            logger.error("â— ObrÃ¡zek nenalezen! Kde je ten pixelovÃ½ poklad? ğŸ–¼ï¸")
            return {"image": None, "message": "â— ObrÃ¡zek nenalezen!"}

        try:
            # NaÄtenÃ­ obrÃ¡zku
            img = cv2.imread(image_path)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # Pokud je Grounding DINO zapnutÃ½, pouÅ¾ijeme ho pro detekci
            if self.grounding_dino and text_prompt:
                logger.info(f"ğŸ” Grounding DINO hledÃ¡: {text_prompt}")
                boxes, confidences, labels = self.grounding_dino.predict(img_rgb, text_prompt)
                if not boxes:
                    logger.warning("âš ï¸ Grounding DINO nic nenaÅ¡el. SAM to zachrÃ¡nÃ­! ğŸ¦¸â€â™‚ï¸")
                    masks = self.sam.generate(img_rgb)
                else:
                    # PÅ™evod boxÅ¯ na masky pÅ™es SAM
                    masks = []
                    for box in boxes:
                        mask = self.sam.generate_from_box(img_rgb, box)
                        masks.append(mask)
            else:
                # Bez Grounding DINO pouÅ¾ijeme jen SAM
                logger.info("ğŸ”§ SAM jede sÃ¡m, Å¾Ã¡dnÃ© fancy detekce!")
                masks = self.sam.generate(img_rgb)

            if not masks:
                logger.warning("âš ï¸ Å½Ã¡dnÃ© masky! MoÅ¾nÃ¡ je obrÃ¡zek jen ÄernÃ¡ dÃ­ra? ğŸŒŒ")
                return {"image": img_rgb, "message": "â— Å½Ã¡dnÃ© masky nenalezeny!"}

            # Kombinace masek do jednÃ©
            combined_mask = np.zeros_like(img_rgb[:, :, 0])
            for mask in masks:
                combined_mask = np.logical_or(combined_mask, mask["segmentation"]).astype(np.uint8)
            
            # Aplikace masky na obrÃ¡zek (odstranÄ›nÃ­ pozadÃ­)
            result = img_rgb.copy()
            result[combined_mask == 0] = 0  # ÄŒernÃ© pozadÃ­
            
            output_path = self.config.OUTPUT_DIR / get_next_output_filename("png")
            cv2.imwrite(str(output_path), cv2.cvtColor(result, cv2.COLOR_RGB2BGR))
            logger.info(f"âœ… Segmentace hotova, vÃ½stup: {output_path}")
            return {
                "image": result,
                "message": f"âœ… PozadÃ­ odstranÄ›no, uloÅ¾eno jako {output_path}"
            }

        except Exception as e:
            logger.error(f"âŒ Segmentace selhala: {e}. Pixely se vzbouÅ™ily! ğŸ˜£")
            return {"image": None, "message": f"â— Chyba: {e}"}

    def blur_background(self, image_path: str, output_path: str, blur_strength: int = 21) -> None:
        """RozmaÅ¾e pozadÃ­ jako po tÅ™ech panÃ¡cÃ­ch. VÅ¡e blurry, Å¾Ã¡dnÃ¡ ostrost! ğŸ»"""
        if not Path(image_path).exists():
            logger.error("â— ObrÃ¡zek nenalezen! Kde je ten pixelovÃ½ poklad? ğŸ–¼ï¸")
            return

        try:
            # NaÄtenÃ­ obrÃ¡zku
            img = cv2.imread(image_path)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # GenerovÃ¡nÃ­ masek pÅ™es SAM
            masks = self.sam.generate(img_rgb)
            if not masks:
                logger.warning("âš ï¸ Å½Ã¡dnÃ© masky! ObrÃ¡zek je asi prÃ¡zdnÃ½ jako hospoda o pÅ¯lnoci! ğŸº")
                cv2.imwrite(output_path, img)
                return

            # Kombinace masek
            combined_mask = np.zeros_like(img_rgb[:, :, 0])
            for mask in masks:
                combined_mask = np.logical_or(combined_mask, mask["segmentation"]).astype(np.uint8)
            
            # RozmazÃ¡nÃ­ pozadÃ­
            blurred = cv2.GaussianBlur(img_rgb, (blur_strength, blur_strength), 0)
            result = img_rgb.copy()
            result[combined_mask == 0] = blurred[combined_mask == 0]
            
            # UloÅ¾enÃ­ vÃ½stupu
            cv2.imwrite(output_path, cv2.cvtColor(result, cv2.COLOR_RGB2BGR))
            logger.info(f"âœ… PozadÃ­ rozmazÃ¡no, vÃ½stup: {output_path}")
        
        except Exception as e:
            logger.error(f"âŒ RozmazÃ¡nÃ­ selhalo: {e}. Pixely jsou poÅ™Ã¡d ostrÃ©! ğŸ˜£")
            cv2.imwrite(output_path, cv2.imread(image_path))  # UloÅ¾Ã­ pÅ¯vodnÃ­ obrÃ¡zek

if __name__ == "__main__":
    # TestovacÃ­ kÃ³d, aÅ¥ vidÃ­me, jak to Å™eÅ¾e! ğŸ”ª
    segmenter = Segmenter(use_grounding_dino=False)
    test_image = "test_image.jpg"
    result = segmenter.text_guided_segmentation(test_image, "ÄlovÄ›k")
    print(result["message"])
    segmenter.blur_background(test_image, str(Path("output") / get_next_output_filename("png")), blur_strength=21)